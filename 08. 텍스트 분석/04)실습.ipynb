{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532c605e-a435-4307-9dfa-fdcf3c980142",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "\n",
    "많은 양의 문서가 있을 때 사람이 처리하기 어려울 때, 토픽 모델링을 사용하여 문서 집합에 숨어 있는 주제를 찾아낼 수 있다.    \n",
    "머신러닝 기반의 토픽 모델은 숨겨진 주제를 효과적으로 표현할 수 있는 중심 단어를 함축적으로 추출한다.    \n",
    "주로 LSA(Latent Semantic Analysis)와 LDA(Latent Dirichlet Allocation) 기법으로 사용된다.    \n",
    "(LDA(Latent Dirichlet Allocaion)과 차원의 축소를 나타내는 LDA(Linear Discriminant Analysis)를 구별하자!)    \n",
    "\n",
    "이전의 실습에 사용했던 뉴스데이터를 가지고 토픽모델링을 진행하겠다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d33b475-35f5-4cfc-81e4-13f62e074d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shape: (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# 모터사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 의학, 우주 주제를 추출. \n",
    "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
    "\n",
    "# 위에서 cats 변수로 기재된 category만 추출. featch_20newsgroups( )의 categories에 cats 입력\n",
    "news_df= fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'), \n",
    "                            categories=cats, random_state=0)\n",
    "\n",
    "#LDA는 Count 기반의 Vectorizer만 적용합니다.  \n",
    "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1,2))\n",
    "feat_vect = count_vect.fit_transform(news_df.data)\n",
    "print('CountVectorizer Shape:', feat_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84565b-fff4-4b03-a86f-07561c4b71a3",
   "metadata": {},
   "source": [
    "LDA 기법을 적용하기 위해 뉴스데이터 주제 중 몇 가지를 추출하였다.    \n",
    "- max_df: 단어의 최대 빈도 (95%이상의 문서에서 등장하는 단어 무시)\n",
    "- max_features: 고려할 최대 단어 수(1000개의 단어만 고려)\n",
    "- min_df: 단어의 최소 빈도 (2개 이하의 문서에 등장하는 단어 무시)\n",
    "- stop_words: english의 stopwords를 제거\n",
    "- ngram_range: 텍스트에서 추출할 ngram의 범위 (1,2)=2개 묶음    \n",
    "    \n",
    "LDA기법은 Count기반의 벡터화만 사용하여 피처벡터화를 진행한다.    \n",
    "CountVectorizer를 사용하여 7862개의 문서 중에서 1000개의 피처로 구성된 행렬데이터가 feat_vect에 저장된 것을 확인할 수 있다.    \n",
    "이후 LatentDirichletAllocation 클래스의 n_components 파라미터를 사용하여 토픽의 개수를 조정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3ead55-3306-4f8d-9675-2f5a82203231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=8, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=8, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=8, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2d556-f7c2-4336-9580-08a7a313abb5",
   "metadata": {},
   "source": [
    "random_state 파라미터는 실습을 수행할때마다 똑같은 결과가 나올 수 있도록 함이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d72bcb-1656-4adb-a93b-980a9c7deca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
       "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
       "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
       "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
       "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
       "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
       "       ...,\n",
       "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
       "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
       "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
       "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
       "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
       "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lda.components_.shape)\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f5de64-0656-4e7c-8472-64602ef84ea7",
   "metadata": {},
   "source": [
    "LatentDirichletAllocation.fit(dataset)을 수행하면 객체는 components_ 속성값을 가지게 되는데 components_는 개별 토픽별로 각 word피처가 얼마나 많이 그 토픽에 할당됐는지에 대한 수치를 가지고 있다. 값이 높을수록 word피처는 토픽의 중심 word로 선정된다.    \n",
    "\n",
    "8개의 토픽별로 1000개의 word 피처가 해당 토픽별로 연관도를 가지고 있다는 것을 알 수 있다.    \n",
    "\n",
    "하지만 lda.components_값만으로는 각 토픽별 word 연관도를 보기가 어렵기 때문에 display_topics()함수를 만들어 각 토픽별로 연관도가 높은 순으로 Word를 나열해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63fae389-69c0-4cda-afe8-7a023d9ea042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic # 0\n",
      "year 10 game medical health team 12 20 disease cancer 1993 games years patients good\n",
      "Topic # 1\n",
      "don just like know people said think time ve didn right going say ll way\n",
      "Topic # 2\n",
      "image file jpeg program gif images output format files color entry 00 use bit 03\n",
      "Topic # 3\n",
      "like know don think use does just good time book read information people used post\n",
      "Topic # 4\n",
      "armenian israel armenians jews turkish people israeli jewish government war dos dos turkey arab armenia 000\n",
      "Topic # 5\n",
      "edu com available graphics ftp data pub motif mail widget software mit information version sun\n",
      "Topic # 6\n",
      "god people jesus church believe christ does christian say think christians bible faith sin life\n",
      "Topic # 7\n",
      "use dos thanks windows using window does display help like problem server need know run\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print('Topic #',topic_index)\n",
    "\n",
    "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array index를 반환. \n",
    "        topic_word_indexes = topic.argsort()[::-1]\n",
    "        top_indexes=topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        # top_indexes대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
    "        feature_concat = ' '.join([feature_names[i] for i in top_indexes])                \n",
    "        print(feature_concat)\n",
    "\n",
    "# CountVectorizer객체내의 전체 word들의 명칭을 get_feature_names_out( )를 통해 추출\n",
    "feature_names = count_vect.get_feature_names_out()\n",
    "\n",
    "# Topic별 가장 연관도가 높은 word를 15개만 추출\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922dd78-d975-40a0-b0f7-9fae797a20fd",
   "metadata": {},
   "source": [
    "Topic #0의 경우 의학에 관련된 주제어가 추출되었고 Topic #2는 컴퓨터그래픽스, Topic #4는 중동언어, Topic #6은 기독교 관련 주제어가 추출된 것을 확인할 수 있다.    \n",
    "Topic #1, #3, #5가 애매한 주제어로 추출되었고 모터사이클과 야구 주제의 경우 명확한 주제어가 추출되지는 않은 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936a0ab-c52f-4088-aaa1-ba3adec5a1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
