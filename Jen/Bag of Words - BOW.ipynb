{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfe9f2a-7a0a-4dd3-8dc4-460705b4c221",
   "metadata": {},
   "source": [
    "# chapter 8. Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f284f-81dd-4a27-ac72-a771ceb381c8",
   "metadata": {},
   "source": [
    "## Bag of Words - BOW\n",
    "\n",
    "**BOW는 문서가 가지는 모든 단어를 문맥이나 순서를 무시한채 일괄적으로 단어의 빈도수를 부여해 Feature 값을 추출하는 Model**이다. <br>\n",
    "1. 문장1과 문장2에 있는 모든 단어에서 중복을 제거하고, 각 단어를 Column 형태로 나열한다. \n",
    "2. 각 단어에 대해 고유 Index를 부여한다.\n",
    "3. 개별 문장에서 해당 단어가 나타나는 횟수를 각 단어(단어 Index)에 기재한다.\n",
    "\n",
    "**BOW 기반 NLP 연구 제한사항**\n",
    "- 문맥 의미 반영 부족\n",
    "- 희소 행렬 문제 : BOW로 Feature Vetorization을 수행하면 희소 행렬 형태의 데이터 세트가 만들어지기 쉽다. 매우 많은 문서에서 단어의 총 갯수는 수만-수십만개가 될 수 있는데, 하나의 문서에 있는 단어는 이 중 극히 일부분이므로 대부분의 데이터는 0값으로 채워지게 된다. \n",
    "\n",
    "### BOW Feature Vectorization\n",
    "\n",
    "머신러닝 알고리즘은 일반적으로 숫자형 Feature를 데이터로 입력받아 동작하기 때문에 텍스트와 같은 데이터는 머신러닝 알고리즘에 바로 입력할 수 없다. <br>\n",
    "따라서 **텍스트는 특정 의미를 가지는 숫자형 값이 Vector 값으로 변환**이 필요하고, 이것을 **Feature Vectorization**이라고 한다. <br>\n",
    "각 문서의 텍스트를 단어로 추출해 Feature로 할당하고, 각 단어의 발생 빈도와 같은 값을 이 Feature 값으로 부여해 각 문서를 이 단어의 Feature 발생 빈도 값으로 구성된 Vector로 만드는 기법이다. <br>\n",
    "\n",
    "**BOW Model에서 Feature Vectorization을 수행한다는 것**은 모든 문서에서 모든 단어를 Column 형태로 나열하고 각 문서에서 해당 단어의 횟수나 정규화된 빈도를 값으로 부여하는 데이터 세트를 Model로 변경하는 것이다. \n",
    "\n",
    "일반적으로 **BOW의 Feature Vectorization은 두 가지 방식**이 있다. \n",
    "1. Count 기반의 Vectorization : 단어 Feature에 값을 부여할 때 각 문서에서 해당 단어가 나타나는 횟수, Count 값을 부여하는 경우 \n",
    "2. TF-IDF(Term Frequency - Inverse Document Frequency) : Count만 부여할 경우 문서의 특징을 나타내기보다는 언어의 특성상 자주 사용될 수 밖에 없는 단어까지 높은 값을 부여하게 된다. 이를 보완하기 위해 TF-IDF를 사용한다. <br>\n",
    "TF-IDF는 개별 문서에서 자주 나타나는 단어에 높은 가중치를 주되, 모든 문서에서 전반적으로 자주 나타나는 단어에 대해서는 패널티를 주는 방식으로 값을 부여한다.  \n",
    "\n",
    "### 사이킷런의 Count 및 TF-IDF Vectorization : CounterVectorizer, TdidfVectorizer\n",
    "\n",
    "사이킷런의 **CountVectorizer** Class는 Count 기반의 Vetorization을 구현한 Class이다. 단지 Feature Vectorization만 수행하지는 않으며 소문자 일괄 변환, 토큰화, 스톱 워드 필터링 등의 텍스트 전처리도 함께 수행한다. <br>\n",
    "CountVectorier도 다른 Feature 변환 Class와 마찬가지로 fit()과 transform()을 통해 Feature Vectorization 된 객체를 반환한다. \n",
    "\n",
    "**CountVectorizer를 이용한 Feature Vectorization**\n",
    "1. 사전 데이터 가공 : 모든 문자를 소문자로 변환하는 등의 사전 작업을 수행한다. (Defualt로 lowcase = True이다.)\n",
    "2. 토큰화 : Defualt는 단어 기준, analyzer = Ture이며 n_gram_range를 반영하여 토큰화를 수행한다.\n",
    "3. 텍스트 정규화 : Stop Words Filtering만 수행한다. Stemmer, Lemmatize는 CountVectorizer 자체에서는 지원되지 않는다. 이를 위한 함수를 만들거나 외부 패키지로 미리 Text Normalzation 수행이 필요하다.\n",
    "4. Feature Vectorization : max_df, min_df, max_features 등의 파라미터를 반영하여 토큰화된 단어들을 Feture Extraction 후 Vectorization 적용\n",
    "\n",
    "사이킷런에서 TF-IDF Vectorization은 **TfidfVectorizer** Class를 이용, 파라미터와 변환 방법은 CountVectorizer와 동일하다. \n",
    "\n",
    "### 사이킷런 CountVetcorizer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c8be3c-3363-4a81-a4c2-f09dc21833f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Matrix is everywhere its all around us, here even in this room.                   You can see it out your window or on your television.                   You feel it when you go to work, or go to church or pay your taxes.', 'You take the blue pill and the story ends.  You wake in your bed and you believe whatever you want to believe                  You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'] \n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "text_sample_01 = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "                  You can see it out your window or on your television. \\\n",
    "                  You feel it when you go to work, or go to church or pay your taxes.'\n",
    "text_sample_02 = 'You take the blue pill and the story ends.  You wake in your bed and you believe whatever you want to believe\\\n",
    "                  You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'\n",
    "text = []\n",
    "text.append(text_sample_01); text.append(text_sample_02)\n",
    "print(text,\"\\n\", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e63d9-2988-49b4-aae9-6b9ef86dfaa4",
   "metadata": {},
   "source": [
    "**CountVectorizer객체 생성 후 fit(), transform()으로 텍스트에 대한 Feature Vectorization 수행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a34d52-d42a-4642-b6ca-0f57585e15a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorization으로 feature extraction 변환 수행\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139ad1a4-4c83-4994-932e-5d961013b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_vect = cnt_vect.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7710d723-5b79-41b4-a020-571d8b9b21d5",
   "metadata": {},
   "source": [
    "**Feature Vectorization 후 데이터 유형 및 여러 속성 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d2dd5a-d4d0-4c28-93fb-bb80e8c376c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'> (2, 51)\n",
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t2\n",
      "  (0, 15)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 20)\t2\n",
      "  (0, 21)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 24)\t3\n",
      "  (0, 25)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 40)\t2\n",
      "  :\t:\n",
      "  (1, 1)\t4\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t2\n",
      "  (1, 5)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 18)\t2\n",
      "  (1, 27)\t2\n",
      "  (1, 28)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 32)\t1\n",
      "  (1, 33)\t1\n",
      "  (1, 34)\t1\n",
      "  (1, 35)\t2\n",
      "  (1, 38)\t4\n",
      "  (1, 40)\t1\n",
      "  (1, 42)\t1\n",
      "  (1, 43)\t1\n",
      "  (1, 44)\t1\n",
      "  (1, 47)\t1\n",
      "  (1, 49)\t7\n",
      "  (1, 50)\t1\n"
     ]
    }
   ],
   "source": [
    "print(type(ftr_vect), ftr_vect.shape)\n",
    "print(ftr_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660505c3-9b65-4523-8d80-053de8d76c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 38, 'matrix': 22, 'is': 19, 'everywhere': 11, 'its': 21, 'all': 0, 'around': 2, 'us': 41, 'here': 15, 'even': 10, 'in': 18, 'this': 39, 'room': 30, 'you': 49, 'can': 6, 'see': 31, 'it': 20, 'out': 25, 'your': 50, 'window': 46, 'or': 24, 'on': 23, 'television': 37, 'feel': 12, 'when': 45, 'go': 13, 'to': 40, 'work': 48, 'church': 7, 'pay': 26, 'taxes': 36, 'take': 35, 'blue': 5, 'pill': 27, 'and': 1, 'story': 34, 'ends': 9, 'wake': 42, 'bed': 3, 'believe': 4, 'whatever': 44, 'want': 43, 'red': 29, 'stay': 33, 'wonderland': 47, 'show': 32, 'how': 17, 'deep': 8, 'rabbit': 28, 'hole': 16, 'goes': 14}\n"
     ]
    }
   ],
   "source": [
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1450b488-bcc3-4b47-9dd2-a107b4004bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'> (2, 5)\n",
      "{'window': 4, 'pill': 1, 'wake': 2, 'believe': 0, 'want': 3}\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer(max_features = 5, stop_words = 'english')\n",
    "cnt_vect.fit(text)\n",
    "ftr_vect = cnt_vect.transform(text)\n",
    "print(type(ftr_vect), ftr_vect.shape)\n",
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05df59e-31a9-4abf-a55c-69e070dbb7f2",
   "metadata": {},
   "source": [
    "**ngram_range 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29bed95a-5a34-406c-8c75-a3078e018519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'> (2, 201)\n",
      "{'the': 129, 'matrix': 77, 'is': 66, 'everywhere': 40, 'its': 74, 'all': 0, 'around': 11, 'us': 150, 'here': 51, 'even': 37, 'in': 59, 'this': 140, 'room': 106, 'you': 174, 'can': 25, 'see': 109, 'it': 69, 'out': 90, 'your': 193, 'window': 165, 'or': 83, 'on': 80, 'television': 126, 'feel': 43, 'when': 162, 'go': 46, 'to': 143, 'work': 171, 'church': 28, 'pay': 93, 'taxes': 125, 'the matrix': 132, 'matrix is': 78, 'is everywhere': 67, 'everywhere its': 41, 'its all': 75, 'all around': 1, 'around us': 12, 'us here': 151, 'here even': 52, 'even in': 38, 'in this': 60, 'this room': 141, 'room you': 107, 'you can': 177, 'can see': 26, 'see it': 110, 'it out': 70, 'out your': 91, 'your window': 199, 'window or': 166, 'or on': 86, 'on your': 81, 'your television': 197, 'television you': 127, 'you feel': 179, 'feel it': 44, 'it when': 72, 'when you': 163, 'you go': 181, 'go to': 47, 'to work': 148, 'work or': 172, 'or go': 84, 'to church': 146, 'church or': 29, 'or pay': 88, 'pay your': 94, 'your taxes': 196, 'the matrix is': 133, 'matrix is everywhere': 79, 'is everywhere its': 68, 'everywhere its all': 42, 'its all around': 76, 'all around us': 2, 'around us here': 13, 'us here even': 152, 'here even in': 53, 'even in this': 39, 'in this room': 61, 'this room you': 142, 'room you can': 108, 'you can see': 178, 'can see it': 27, 'see it out': 111, 'it out your': 71, 'out your window': 92, 'your window or': 200, 'window or on': 167, 'or on your': 87, 'on your television': 82, 'your television you': 198, 'television you feel': 128, 'you feel it': 180, 'feel it when': 45, 'it when you': 73, 'when you go': 164, 'you go to': 182, 'go to work': 49, 'to work or': 149, 'work or go': 173, 'or go to': 85, 'go to church': 48, 'to church or': 147, 'church or pay': 30, 'or pay your': 89, 'pay your taxes': 95, 'take': 121, 'blue': 22, 'pill': 96, 'and': 3, 'story': 118, 'ends': 34, 'wake': 153, 'bed': 14, 'believe': 17, 'whatever': 159, 'want': 156, 'red': 103, 'stay': 115, 'wonderland': 168, 'show': 112, 'how': 56, 'deep': 31, 'rabbit': 100, 'hole': 54, 'goes': 50, 'you take': 187, 'take the': 122, 'the blue': 130, 'blue pill': 23, 'pill and': 97, 'and the': 6, 'the story': 138, 'story ends': 119, 'ends you': 35, 'you wake': 189, 'wake in': 154, 'in your': 64, 'your bed': 194, 'bed and': 15, 'and you': 8, 'you believe': 175, 'believe whatever': 18, 'whatever you': 160, 'you want': 191, 'want to': 157, 'to believe': 144, 'believe you': 20, 'the red': 136, 'red pill': 104, 'you stay': 185, 'stay in': 116, 'in wonderland': 62, 'wonderland and': 169, 'and show': 4, 'show you': 113, 'you how': 183, 'how deep': 57, 'deep the': 32, 'the rabbit': 134, 'rabbit hole': 101, 'hole goes': 55, 'you take the': 188, 'take the blue': 123, 'the blue pill': 131, 'blue pill and': 24, 'pill and the': 98, 'and the story': 7, 'the story ends': 139, 'story ends you': 120, 'ends you wake': 36, 'you wake in': 190, 'wake in your': 155, 'in your bed': 65, 'your bed and': 195, 'bed and you': 16, 'and you believe': 9, 'you believe whatever': 176, 'believe whatever you': 19, 'whatever you want': 161, 'you want to': 192, 'want to believe': 158, 'to believe you': 145, 'believe you take': 21, 'take the red': 124, 'the red pill': 137, 'red pill and': 105, 'pill and you': 99, 'and you stay': 10, 'you stay in': 186, 'stay in wonderland': 117, 'in wonderland and': 63, 'wonderland and show': 170, 'and show you': 5, 'show you how': 114, 'you how deep': 184, 'how deep the': 58, 'deep the rabbit': 33, 'the rabbit hole': 135, 'rabbit hole goes': 102}\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer(ngram_range = (1, 3))\n",
    "cnt_vect.fit(text)\n",
    "ftr_vect = cnt_vect.transform(text)\n",
    "print(type(ftr_vect), ftr_vect.shape)\n",
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc15bcb-3a0f-40b6-ae2a-552ac2a8ec18",
   "metadata": {},
   "source": [
    "### BOW Vectorization을 위한 희소 행렬\n",
    "\n",
    "대규모 행렬의 대부분의 값을 0이 차지하는 행렬을 가리켜 **희소 행렬**이라고 한다. <br>\n",
    "**BOW 형태를 가진 언어 모델의 Feature Vectorization은 대부분 희소행렬**이다. 희소 행렬은 너무 많은 불필요한 0 값이 메모리 공간에 할당되어 많은 메모리 공간을 필요로하며, 행렬의 크기가 너무 커서 연산 시에도 데이터를 엑세스하기 위한 시간이 많이 소모된다. <br>\n",
    "이러한 희소 행렬을 물리적으로 적은 메모리를 사용하도록 변환해야하고 **COO 형식**과 **CSR 형식**을 사용한다. \n",
    "\n",
    "### 희소 행렬 - COO 형식 \n",
    "\n",
    "**COO(Coordinate) 형식은 0이 아닌 데이터만 별도의 데이터 배열에 저장하고, 그 데이터가 가리키는 행과 열의 위치를 별도의 배열로 저장하는 방식**이다. <br>\n",
    "Python에서는 희소 행렬 변환을 위해 주로 Scipy를 이용한다. Scipy의 sparse 패키지는 희소 행렬 변환을 위한 다양한 모듈을 제공한다. <br>\n",
    "0이 아닌 데이터를 별도의 배열 데이터로 만들고, 행 위치 배열과 열 위치 배열을 각각 만든 후 **coo_matrix()** 내에 생성 파라미터로 입력하면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98856673-6b24-4b06-b252-21c2d5adc6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dense = np.array([[3, 0, 1], \n",
    "                    [0, 2, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44aed930-63cf-43e9-a846-9fcc9e0d19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# 0이 아닌 데이터 추출\n",
    "data = np.array([3, 1, 2])\n",
    "\n",
    "# 행 위치와 열 위치를 각각 array로 생성 \n",
    "row_pos = np.array([0, 0, 1])\n",
    "col_pos = np.array([0, 2, 1])\n",
    "\n",
    "# sparse 패키지의 coo_matrix를 이용하여 COO 형식으로 희소 행렬 생성\n",
    "sparse_coo = sparse.coo_matrix((data, (row_pos, col_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca4e0026-3f0f-46b2-81e9-d3265bdd4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._coo.coo_matrix'>\n",
      "  (0, 0)\t3\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t2\n",
      "<class 'numpy.ndarray'> \n",
      " [[3 0 1]\n",
      " [0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "print(type(sparse_coo))\n",
    "print(sparse_coo)\n",
    "dense01 = sparse_coo.toarray()\n",
    "print(type(dense01), \"\\n\", dense01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e3463-8f04-4f6c-8cda-d931e2423301",
   "metadata": {},
   "source": [
    "### 희소 행렬 - CSR 형식\n",
    "\n",
    "**CSR(Compressed Sparse Row) 형식은 COO 형식이 행과 열의 위치를 나타내기 위해서 반복적인 위치 데이터를 사용해야하는 문제점을 해결한 방식**이다. <br>\n",
    "0이 아닌 데이터를 배열과 열의 위치 배열, 그리고 행의 위치 배열의 고유한 값의 시작 위치 배열을 **csr_matrix()** 생성 파라미터로 입력하면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a822687-b3b9-4dda-920a-61a99d0a3496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n",
      "CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "dense2 = np.array([[0, 0, 1, 0, 0, 5],\n",
    "             [1, 4, 0, 3, 2, 5], \n",
    "             [0, 6, 0, 3, 0, 0],\n",
    "             [2, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 7, 0, 8],\n",
    "             [1, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# 0 이 아닌 데이터 추출\n",
    "data2 = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n",
    "\n",
    "# 행 위치와 열 위치를 각각 array로 생성 \n",
    "row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])\n",
    "col_pos = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])\n",
    "\n",
    "# COO 형식으로 변환 \n",
    "sparse_coo = sparse.coo_matrix((data2, (row_pos,col_pos)))\n",
    "\n",
    "# 행 위치 배열의 고유한 값들의 시작 위치 인덱스를 배열로 생성\n",
    "row_pos_ind = np.array([0, 2, 7, 9, 10, 12, 13])\n",
    "\n",
    "# CSR 형식으로 변환 \n",
    "sparse_csr = sparse.csr_matrix((data2, col_pos, row_pos_ind))\n",
    "\n",
    "print('COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
    "print(sparse_coo.toarray())\n",
    "print('CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
    "print(sparse_csr.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812fa945-627e-40c2-abd3-67f5ff53e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 5)\t5\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t4\n",
      "  (1, 3)\t3\n",
      "  (1, 4)\t2\n",
      "  (1, 5)\t5\n",
      "  (2, 1)\t6\n",
      "  (2, 3)\t3\n",
      "  (3, 0)\t2\n",
      "  (4, 3)\t7\n",
      "  (4, 5)\t8\n",
      "  (5, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "print(sparse_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e494be-70d5-4214-a6ee-7be44650739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense3 = np.array([[0, 0, 1, 0, 0, 5],\n",
    "             [1, 4, 0, 3, 2, 5],\n",
    "             [0, 6, 0, 3, 0, 0],\n",
    "             [2, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 7, 0, 8],\n",
    "             [1, 0, 0, 0, 0, 0]])\n",
    "\n",
    "coo = sparse.coo_matrix(dense3)\n",
    "csr = sparse.csr_matrix(dense3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
