{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abfad490",
   "metadata": {},
   "source": [
    "# chapter 4. Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c7733",
   "metadata": {},
   "source": [
    "## Classification Basic\n",
    "\n",
    "**지도 학습**은 레이블, 즉 **명시적인 정답이 있는 데이터가 주어진 상태에서 학습하는 머신러닝 방식**이다. <br>\n",
    "지도학습의 **대표적인 유형인 분류는 학습 데이터**로 주어진 데이터의 피처와 레이블값을 머신러닝 알고리즘으로 학습해 모델을 생성, 생성된 모델에 새로운 데이터 값이 주어졌을 때 미지의 레이블 값을 예측하는 것이다. <br>\n",
    "기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤에 새롭게 관측된 데이터에 대한 레이블을 판별하는 것이다. <br>\n",
    "\n",
    "**분류는 다양한 머신러닝 알고리즘으로 구현**할 수 있다. <br>\n",
    "1. 베이즈(Bayes) 통계와 생성 모델에 기반한 나이브 베이즈(Naive Bayes) <br>\n",
    "2. 독립 변수와 종속 변수의 선형 관계성에 기반한 로지스틱 회귀 <br>\n",
    "3. 데이터 균일도에 따른 규칙 기반의 결정 트리 <br>\n",
    "4. 개별 클래스 간의 최대 분류 마진을 효과적으로 찾아주는 서포트 백터 머신(Support Vector Machine) <br>\n",
    "5. 근접 거리를 기준으로 하는 최소 근접 알고리즘 <br>\n",
    "6. 심층 연결 기반의 신경망(Neural Network) <br>\n",
    "7. 서로 다른 / 또는 같은 머신러닝 알고리즘을 결합한 앙상블(Ensemble) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db00005b",
   "metadata": {},
   "source": [
    "**앙상블 / Ensemble Method**\n",
    "\n",
    "**정형 데이터의 예측 분석 영역**에서는 **앙상블이 매우 높은 예측 성능으로 인해 많은 분석가와 데이터 과학자들에게 애용**되고 있다. <br>\n",
    "앙상블은 서로 다른 / 또는 같은 알고리즘을 단순히 결합한 형태도 있으나 일반적으로는 **배깅(Bagging)** 과 **부스팅(Boosting)** 방식으로 나뉜다. <br>\n",
    "**배깅 방식**의 대표인 **랜덤 포레스트(Random Forest)** 는 뛰어난 예측 성능, 상대적으로 빠른 수행 시간, 유연성 등으로 많은 분석가가 애용하는 알고리즘이다. <br>\n",
    "\n",
    "근래의 앙상블은 부스팅 방식으로 지속해서 발전하고 있다. <br>\n",
    "부스팅의 효시라고 할 수 있는 **그래디언트 부스팅(Gradient Boosting)** 의 경우 뛰어난 예측 성능을 가지고 있지만, 수행 시간이 오래 걸리는 단점으로 최적화 모델 튜닝이 어려웠다. <br>\n",
    "XgBoost와 LightGBM 등 기존의 그래디언트 부스팅의 예측 성능을 한단계 발전시키면서도 수행 시간을 단축시킨 알고리즘이 등장하며 정형 데이터의 분류 영역에서 가장 활용도가 높은 알고리즘으로 자리잡았다. <br>\n",
    "\n",
    "**앙상블은 대부분 동일한 알고리즘을 결합**한다. <br>\n",
    "**앙상블의 기본 알고리즘**으로 일반적으로 사용하는 것은 **결정 트리**이다. <br>\n",
    "결정 트리는 매우 쉽고 유연하게 적용될 수 있는 알고리즘이다. <br>\n",
    "데이터의 스케일링이나 정규화등의 사전 가공의 영향이 매우 적다. <br>\n",
    "예측 성능을 향상시키기 위해 복잡한 규칙 구조를 가져야하며, 이로 인한 **과적합(Overfiting)** 이 발생해 예측 성능이 저하될 수 있다는 단점이 있지만, **앙상블 기법에서는 이러한 단점이 오히려 장점으로 작용**한다. <br>\n",
    "매우 많은 여러 개의 **약한 학습기(예측 성능이 상대적으로 떨어지는 학습 알고리즘)를 결합**해 확률적 보완과 오류가 발생한 부분에 대한 **가중치를 계속 업데이트하면서 예측 성능을 향상**시키는데 **결정 트리가 좋은 약한 학습기**가 되기 때문이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
