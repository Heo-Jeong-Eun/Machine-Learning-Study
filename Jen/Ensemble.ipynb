{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22350932",
   "metadata": {},
   "source": [
    "# chapter 4. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4096c",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "\n",
    "**앙상블 학습을 통한 분류**는 **여러 개의 분류기를 생성하고 그 예측을 결합함으로써 보다 정확한 최종 예측을 도출하는 기법**을 말한다. <br>\n",
    "**정형 데이터 분류시에는 앙상블이 뛰어난 성능**을 나타내고 있다. <br>\n",
    "**랜덤 포레스트**와 **그래디언트 부스팅 알고리즘**은 뛰어난 성능과 쉬운 사용, 다양한 활용도로 인해 그간 분석가 및 데이터 과학자들 사이에서 많이 애용되었다. <br> \n",
    "\n",
    "앙상블 학습 유형은 전통적으로 **보팅(Voting), 배깅(Bagging), 부스팅(Boosting)** 의 세가지로 나눌 수 있다. <br>\n",
    "**보팅과 배깅은** 여러 개의 분류기가 **투표를 통해 최종 예측 결과를 결정**하는 방식이다. <br>\n",
    "보팅과 배깅의 다른 점은 보팅의 경우 일반적으로 서로 다른 알고리즘을 가진 분류기를 결합하는 것이고, 배깅의 경우 각각의 분류기가 모두 같은 유형의 알고리즘 기반이지만, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행해 보팅을 수행해야 하는 것이다. <br>\n",
    "**대표적인 배깅 방식이 바로 랜덤 포레스트 알고리즘**이다. <br>\n",
    "\n",
    "<img src = 'image/Voting and Bagging.jpg' alt = 'Voting and Bagging' width='600' height='600'>\n",
    "\n",
    "왼쪽 그림은 **보팅 분류기**를 도식화한 것이고, 오른쪽 그림은 **배팅 분류기**를 도식화한 것이다. <br>\n",
    "\n",
    "**개별 Classifier에 데이터를 샘플링해서 추출하는 방식을 부스트트래핑(Boosttrapping) 분할 방식**이라고 부른다. <br>\n",
    "개별 분류기가 부스트트래핑 방식으로 샘플링 된 데이터 세트에 대해서 학습을 통해 개별적인 예측을 수행한 결과를 보팅을 통해서 최종 예측 결과를 선정하는 방식이 바로 **배깅 앙상블 방식**이다. <br>\n",
    "배깅 방식은 중첩을 허용한다. <br>\n",
    "\n",
    "부스팅은 여러 개의 분류기가 순차적으로 학습을 수행하되, 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서는 올바르게 예측할 수 있도록 다름 분류기에게는 가중치를 부여하면서 학습과 예측을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd234b7",
   "metadata": {},
   "source": [
    "### 하드 보팅(Hard Voting)과 소프트 보팅(Soft Voting)\n",
    "\n",
    "보팅 방법은 **하드 보팅**과  **소프트 보팅** 두 가지가 있다. <br>\n",
    "**하드 보팅**을 이용한 분류는 **예측한 결과값들 중 다수의 분류기가 결정한 예측값을 최종 보팅 결과값으로 선정**하는 것이다. <br>\n",
    "**소프트 보팅**은 **분류기들의 레이블 값 결정 확률을 모두 더하고 이를 평균해서 이들 중 가장 높은 레이블 값을 최종 보팅 결과값으로 선정**한다. <br>\n",
    "\n",
    "<img src = 'image/Hard Voting and Soft Voting.jpg' alt = 'Hard Voting and Soft Voting' width='600' height='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b543ea3",
   "metadata": {},
   "source": [
    "### 보팅 분류기(Voting Classifier)\n",
    "\n",
    "사이킷런은 보팅 방식의 앙상블을 구현한 **Voting Classifier 클래스**를 제공한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacfe9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7f848",
   "metadata": {},
   "source": [
    "**VotingClassifier 클래스**는 주로 **생성 인자로 estimators와 voting 값을 입력받는다.** <br>\n",
    "**estimators**는 리스트 값으로 보팅에 사용될 여러 개의 Classifier 객체들을 튜플 형식으로 입력받으며 **voting**은 hard 시 하드 보팅, soft 시 소프트 보팅을 적용하라는 의미이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9d73d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도 : 0.9561\n",
      "LogisticRegression 정확도 : 0.9474\n",
      "KNeighborsClassifier 정확도 : 0.9386\n"
     ]
    }
   ],
   "source": [
    "# 개별 모델은 로지스틱 회귀와 KNN이다. \n",
    "lr_clf = LogisticRegression(solver = 'liblinear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기\n",
    "vo_clf = VotingClassifier(estimators = [('LR', lr_clf), ('KNN', knn_clf)], voting = 'soft')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                   test_size = 0.2, random_state = 156)\n",
    "\n",
    "# VotingClassifier 학습 / 예측 / 평가\n",
    "vo_clf.fit(X_train, Y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도 : {0:.4f}'.format(accuracy_score(Y_test, pred)))\n",
    "\n",
    "# 개별 모델의 학습 / 예측 / 평가\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name = classifier.__class__.__name__\n",
    "    print('{0} 정확도 : {1:.4f}'.format(class_name, accuracy_score(Y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361c302",
   "metadata": {},
   "source": [
    "보팅으로 여러 개의 기반 분류기를 결합한다고 해서 무조건 기반 분류기보다 예측 성능이 향상되지는 않는다. <br>\n",
    "다양한 요건에 따라 오히려 기반 분류기 중 가장 좋은 분류기의 성능이 보팅했을 때보다 나을 수도 있다. <br>\n",
    "그럼에도 불구하고 보팅을 포함한 배깅과 부스팅의 앙상블 방법은 단일 ML 알고리즘보다 뛰어난 예측 성능을 가지는 경우가 많다. <br>\n",
    "\n",
    "**ML 모델의 성능은 이렇게 다양항 테스트 데이터에 의해 검증되므로 어떻게 높은 유연성을 가지고 현실에 대처할 수 있는가가 중요한 ML 모델의 평가 요소가 된다.** <br>\n",
    "편향-분산 트레이드오프는 ML 모델이 극복해야 할 중요한 과제이다. <br>\n",
    "\n",
    "**배깅과 부스팅은 대부분 결정 트리 알고리즘을 기반**으로 한다. <br>\n",
    "앙상블 학습에서는 결정 트리 알고리즘의 단점을 수십-수천개의 매우 많은 분류기를 결합해 다양한 상황을 학습하게 함으로써 극복하고 있다. <br>\n",
    "**결정 트리 알고리즘의 장점은 그대로 취하고 단점은 보완하면서 편향-분산 트레이드오프의 효과를 극대화할 수 있다는 것**이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
