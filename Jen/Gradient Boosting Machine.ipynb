{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04523d9",
   "metadata": {},
   "source": [
    "# chapter 4. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59dac81",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine\n",
    "\n",
    "### GBM의 개요 및 실습\n",
    "\n",
    "**부스팅 알고리즘**은 **여러 개의 약한 학습기를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치 부여를 통해 오류를 개선해나가면서 학습하는 방식**이다. <br>\n",
    "부스팅의 대표적인 구현은 **AdaBoost(Adaptive Boosting)** 와 **그래디언트 부스트**가 있다. <br>\n",
    "**에이다 부스트**는 오류 데이터에 가중치를 부여하면서 부스팅을 수행하는 대표적인 알고리즘이다. <br>\n",
    "\n",
    "**GBM**은 CART 기반의 다른 알고리즘과 마찬가지로 **분류, 회귀가 가능**하다. <br>\n",
    "사이킷런은 **GBM 기반의 분류를 위해 GradientBoostingClassifier 클래스를 제공**한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e56677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 피처명에서 10개만 추출 :  ['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z', 'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z', 'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z', 'tBodyAcc-max()-X']\n"
     ]
    }
   ],
   "source": [
    "# 이전 Random Forest Data\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# feature.txt 파일에는 피처 이름 index와 피처명이 공백으로 분리되어 있다. -> DataFrame으로 Load\n",
    "feature_name_df = pd.read_csv('/Users/1001l1000/Documents/AI/Jen/data/human_activity/features.txt', sep = '\\s+',\n",
    "                             header = None, names = ['column_index', 'column_name'])\n",
    "\n",
    "# 피처명 index를 제거하고, 피처명만 리스트 객체로 생성한 뒤 샘플로 10개만 추출\n",
    "feature_name = feature_name_df.iloc[:, 1].values.tolist()\n",
    "print('전체 피처명에서 10개만 추출 : ', feature_name[:10])\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data = old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                 columns = ['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how = 'outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', \n",
    "                                                              'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1])\n",
    "                                                                               if x[1] > 0 else x[0], axis = 1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis = 1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "def get_human_dataset( ): \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('/Users/1001l1000/Documents/AI/Jen/data/human_activity/features.txt',sep = '\\s+',\n",
    "                        header = None, names = ['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('/Users/1001l1000/Documents/AI/Jen/data/human_activity/train/X_train.txt', sep = '\\s+', names = feature_name )\n",
    "    X_test = pd.read_csv('/Users/1001l1000/Documents/AI/Jen/data/human_activity/test/X_test.txt', sep = '\\s+', names = feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('/Users/1001l1000/Documents/AI/Jen/data/human_activity/train/y_train.txt', sep = '\\s+',header = None, names = ['action'])\n",
    "    y_test = pd.read_csv('/Users/1001l1000/Documents/AI/Jen/data/human_activity/test/y_test.txt', sep = '\\s+',header = None, names = ['action'])\n",
    "    \n",
    "    # 로드된 학습 / 테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행 시간 측정을 위한 것이다. 시작 시간 설정\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state = 0)\n",
    "gb_clf.fit(X_train, Y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(Y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도 : {0:.4f}'.format(gb_accuracy))\n",
    "print('GBM 수행 시간 : {0:.1f} 초'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6363896e",
   "metadata": {},
   "source": [
    "특히 수행 시간 문제는 GBM이 해결해야 할 문제이다. <br>\n",
    "사이킷런의 GradientBoostingClassifier는 약한 학습기의 순차적인 예측 오류 보정을 통해 학습을 수행하므로 멀티 CPU 코어 시스템을 사용하더라도 병렬 처리가 지원되지 않아서 대용량 데이터의 경우 학습에 매우 많은 시간이 필요하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d91565",
   "metadata": {},
   "source": [
    "### GBM 하이퍼 파라미터 \n",
    "\n",
    "- loss : 경사 하강법에서 사용할 비용 함수를 지정한다. 특별한 이유가 없으면 기본값인 deviance를 그대로 적용한다. <br>\n",
    "- learning_rate : GBM이 학습을 진행할 때마다 적용하는 학습률이다. <br>\n",
    "- n_estimators : weak learner의 갯수이다. <br>\n",
    "- subsample : weak learner가 학습에 사용하는 데이터의 샘플링 비율이다. 기본값은 1이고 이는 전체 학습 데이터를 기반으로 학습한다는 의미이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
