{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b87879",
   "metadata": {},
   "source": [
    "# chapter 5. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcb2aa",
   "metadata": {},
   "source": [
    "## Understanding Regression with Simple Linear Regression\n",
    "\n",
    "단순 선형 회귀는 독립 변수도 하나, 종속 변수도 하나인 선형 회귀이다. <br> \n",
    "\n",
    "실제 값과 회귀 모델의 차이에 따른 오류 값을 남은 오류, 즉 **잔차**라고 부른다. <br> \n",
    "**최적의 회귀 모델을 만든다는 것은 바로 전체 데이터의 잔차 합이 최소가 되는 모델을 만든다는 의미**이고, **동시에 오류 값의 합이 최소가 될 수 있는 최적의 회귀 계수를 찾는다는 의미**도 된다. \n",
    "\n",
    "오류 값은 +나 -가 될 수 있다. 따라서 전체 데이터의 오류 합을 구하기 위해 단순히 더하게 되면 뜻하지 않게 오류의 합이 크게 줄어들 수 있다. <br>\n",
    "따라서 보통 **오류의 합을 계산할 때는 절대값을 취해 더하거나, 오류 값의 제곱을 구해서 더하는 방식인 RSS**를 취한다. <br>\n",
    "일반적으로 미분 등의 계산을 편리하게 하기 위해서 RSS 방식으로 오류 합을 구한다. <br>\n",
    "**Error^2 = RSS** <br>\n",
    "\n",
    "**머신러닝 회귀 알고리즘은 데이터를 계속 학습하면서 비용함수가 반환하는 값, 즉 오류값을 지속해서 감소시키고 최종적으로는 더이상 감소하지 않는 최소의 오류값을 구하는 것이다.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
