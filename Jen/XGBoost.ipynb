{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf0e314",
   "metadata": {},
   "source": [
    "# chapter 4. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5941be16",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "### XGBoost 개요\n",
    "\n",
    "**XGBoost**는 트리 기반의 앙상블 학습에서 가장 각광받고 있는 알고리즘 중 하나이다. <br>\n",
    "분류에 있어서 일반적으로 다른 머신러닝보다 **뛰어난 예측 성능**을 나타낸다. <br>\n",
    "XGBoost는 **GBM에 기반**하고 있지만, **GBM의 단점인 느린 수행 시간 및 과적합 규제 부재 등의 문제를 해결**할 수 있다. <br>\n",
    "XGBoost는 **병렬 CPU 환경에서 병렬 학습이 가능**해 기존 GBM보다 빠르게 학습을 완료할 수 있다. <br>\n",
    "\n",
    "**XGBoost 장점**\n",
    "\n",
    "**뛰어난 예측 성능**, 일반적으로 분류와 회귀 영역에서 뛰어난 예측 성능을 발휘한다. <br>\n",
    "**GBM 대비 빠른 수행시간**, 병렬 수행 및 다양한 기능으로 GBM에 비해 빠른 성능을 보장한다. <br>\n",
    "**과적합 규제**, 자체 과적합 규제 기능으로 좀 더 강한 내구성을 가질 수 있다. <br>\n",
    "**Tree Pruning**, 더 이상 긍정 이득이 없는 분할을 가지치기 해서 분할 수를 더 줄이는 추가적인 장점을 가지고 있다. <br>\n",
    "**자체 내장된 교차 검증**, XGBoost는 반복 수행마다 내부적으로 학습 데이터 세트와 평가 데이터 세트에 대한 교차 검증을 수행해 최적화된 반복 수행 횟수를 가질 수 있다. <br>\n",
    "\n",
    "XGBoost의 핵심 라이브러리는 C / C++로 작성 되어있다. <br>\n",
    "XGBoost는 파이썬에서도 XGBoost를 구동할 수 있도록 파이썬 패키지를 제공하고, 이 패키지의 역할은 C / C++ 핵심 라이브러리를 호출하는 것이다. <br>\n",
    "**XGBoost의 파이썬 패키지명은 xgboost**이다. <br>\n",
    "XGBoost 패키지의 사이킷런 래퍼 클래스는 **XGBClassifier**와 **XGBRegressor**이다. <br>\n",
    "사이킷런은 estimator가 학습을 위해 사용하는 fit()과 predict()와 같은 표준 사이킷런 개발 프로세스 및 다양한 유틸리티를 활용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d65eeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c108f25c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'XBGClassifier' from 'xgboost' (/Users/1001l1000/opt/anaconda3/envs/J/lib/python3.9/site-packages/xgboost/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XBGClassifier\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'XBGClassifier' from 'xgboost' (/Users/1001l1000/opt/anaconda3/envs/J/lib/python3.9/site-packages/xgboost/__init__.py)"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XBGClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ec4e5",
   "metadata": {},
   "source": [
    "### 파이썬 래퍼 XGBoost 하이퍼 파라미터 \n",
    "\n",
    "파이썬 래퍼 XGBoost 하이퍼 파라미터 유형\n",
    "\n",
    "- 일반 파라미터 : 일반적으로 실행 시 스레드의 개수나 silent 모드 등 선택을 위한 파라미터로서 디폴트 파라미터 값을 바꾸는 경우는 거의 없다. \n",
    "- 부스터 파라미터 : 트리 최적화, 부스팅, reaularization 등과 관련 파라미터를 지칭한다.\n",
    "- 학습 태스크 파라미터 : 학습 수행시의 객체 함수, 평가를 위한 지표 등을 설정하는 파라미터이다. \n",
    "\n",
    "    \n",
    "|주요 일반 파라미터|내용|\n",
    "|:------|:---|\n",
    "|booster|gbtree, gblinear 선택. 디폴트는 gbtree이다.|\n",
    "|silent|디폴트는 0이며 출력 메시지를 나타내고 싶지 않을 경우 1로 설정한다.|\n",
    "|nthread|CPU의 실행 스레드 개수를 조정하며, 디폴트는 CPU의 전체 스레드를 다 사용하는 것이다. |\n",
    "\n",
    "|주요 부스터 파라미터|내용|\n",
    "|:------|:---|\n",
    "|eta[default = 0.3, alias : learning_rate]|GBM의 학습률과 같은 파라미터이다.|\n",
    "|num_boost_rounds|GBM의 n_estimators와 같은 파라미터이다. |\n",
    "|min_child_weight[default = 1]|트리에서 추가적으로 가지를 나눌지 결정하기 위해 필요한 데이터의 weight 총합|\n",
    "|gamma[default = 0, alias : min_split_loss]|트리의 리프 노드를 추가적으로 나눌지를 결정할 최소 손실 감소값이다. |\n",
    "|max_depth[default = 6]|트리 기반알고리즘의 max_depth와 같다. |\n",
    "|sub_sample[default = 1]|GBM의 subsample과 동일하다. |\n",
    "|colsample_bytree[default = 1]|GBM의 max_feature와 유사하다. |\n",
    "|lambda[default = 1, alias : reg_lambda]|L2 Regularization 적용값이다. |\n",
    "|alpha[default = 0, ailas : reg_alpha]|L1 Regularization 적용 값이다. |\n",
    "|scale_pos_weight[default = 1]|특정 값으로 치우친 비대칭한 클래스로 구성된 데이터 세트의 균형을 유지하기 위한 파라미터이다. |\n",
    "\n",
    "|학습 태스크 파라미터|내용|\n",
    "|:------|:---|\n",
    "|objective|최솟값을 가져야할 손실 함수를 정의한다. |\n",
    "|binary : logistic|이진 분류일 때 적용한다. |\n",
    "|multi : softmax|다중 분류일 때 적용한다. |\n",
    "|multi : softprob|multi : softmax와 유사하나 개별 레이블 클래스의 해당되는 에측 확률을 반환한다. |\n",
    "|eval_metric|검증에 사용되는 함수를 정의한다. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57235e0",
   "metadata": {},
   "source": [
    "**과적합 문제가 심각할 때 적용할 방법**\n",
    "\n",
    "- eta 값을 낮춘다. eta 값을 낮출 경우 num_round 는 반대로 높여줘야 한다. \n",
    "- max_depth 값을 낮눈다.\n",
    "- min_child_weight 값을 높인다. \n",
    "- gamma 값을 높인다. \n",
    "- subsample과 colsample_bytree를 조정하는 것도 트리가 너무 복잡하게 생성되는 것을 막아 과적합 문제에 도움이 될 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98561077",
   "metadata": {},
   "source": [
    "**XGBoost 자체적으로 교차 검증, 평가, 피처 중요도 등의 시각화 기능**을 가지고 있다. <br>\n",
    "수행 속도를 향상시키기 위해 대표적인 기능으로 조기 중간 기능이 있다. <br>\n",
    "기본 GBM의 경우 n_estimators에 지정된 횟수만큼 반복적으로 학습 오류를 감소시키며 학습 진행을 하면서 중간에 반복을 멈출 수 없고 n_estimators에 지정된 횟수를 다 완료해야 한다. <br>\n",
    "\n",
    "**XGBoost는 부스팅 반복 횟수에 도달하지 않더라도 예측 오류가 더 이상 개선되지 않으면 반복을 끝까지 수행하지 않고 중지해 수행 시간을 개선할 수 있다.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f520f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4b94b",
   "metadata": {},
   "source": [
    "### 파이선 래퍼 XGBoost 적용 - 위스콘신 유방암 예측\n",
    "\n",
    "xgboost 패키지는 피처의 중요도를 시각화해주는 모듈인 plot_importance를 함께 제공하고 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f136e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.05667  ...          23.41            158.8      1956.0   \n",
       "2                 0.05999  ...          25.53            152.5      1709.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "features = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data = features, columns = dataset.feature_names)\n",
    "cancer_df['target'] = labels\n",
    "cancer_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9101795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "1    357\n",
      "0    212\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)\n",
    "print(cancer_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872615a",
   "metadata": {},
   "source": [
    "1 값인 양성이 benign이 357개, 악성 malignant가 212개로 구성되어있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf3b9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n",
      "(409, 30) (46, 30)\n"
     ]
    }
   ],
   "source": [
    "# cancer_df에서 feature용 DataFrame과 Label용 Series 객체 추출\n",
    "# 맨 마지막 colunm이 Label이다. feature용 DataFrame은 cancer_df의 첫번째 column에서 맨 마지막 두번째 column까지를 :-1 슬라이싱으로 추출한다.\n",
    "\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "Y_label = cancer_df.iloc[:, -1]\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_features, Y_label, test_size = 0.2, random_state = 156)\n",
    "                                         \n",
    "# X_train, Y_train을 다시 쪼개 90%은 학습과 10%은 검증용 데이터로 분리 \n",
    "X_tr, X_val, Y_tr, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 156)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_tr.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6c6613",
   "metadata": {},
   "source": [
    "파이썬 래퍼 XGBoost는 사이킷런과 여러 가지 차이가 있지만, 먼저 눈에 띄는 차이는 XGBoost만의 전용 데이터 객체인 DMatrix를 사용한다는 점이다. <br>\n",
    "**DMatrix의 주요 입력 파라미터는 data와 label**이다. <br>\n",
    "data는 피처 데이터 세트, label은 분류의 경우에는 레이블 데이터 세트, 회귀의 경우는 숫자형 종속 값 데이터 세트이다. <br>\n",
    "DMatrix는 Numpy, DataFrame, Series 외에 libsvm txt 포맷 파일, xgboost 이진 버퍼 파일을 파라미터로 입력 받아 변환할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b3a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 구버전 XGBoost에서 DataFrame으로 DMatrix 생성이 안될 경우 X_train.value로 Numpy 변환\n",
    "# 학습, 검증, 테스트용 DMatrix를 생성한다. \n",
    "\n",
    "dtr = xgb.DMatrix(data = X_tr, label = Y_tr)\n",
    "dval = xgb.DMatrix(data = X_val, label = Y_val)\n",
    "dtest = xgb.DMatrix(data = X_test, label = Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec189ee8",
   "metadata": {},
   "source": [
    "파이썬 래퍼 XGBoost 모듈인 xgboost를 이용해 학습을 수행하기 전에 먼저 XGBoost의 하이퍼 파라미터를 설정한다. <br>\n",
    "XGBoost의 하이퍼 파라미터는 주로 딕셔너리 형태로 입력한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76f5d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth' : 3,\n",
    "         'eta' : 0.05, \n",
    "         'objective' : 'binary:logistic', \n",
    "         'eval_metric' : 'logloss'\n",
    "         }\n",
    "\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664474e",
   "metadata": {},
   "source": [
    "조기 중단의 성능 평가는 주로 별도의 검증 데이터 세트를 이용한다. <br>\n",
    "조기 중단은 xgboost의 train() 함수의 early_stopping_rounds 파라미터를 입력해 설정한다. <br>\n",
    "반드시 평가용 데이터 세트 지정과 eval_metric을 함께 설정해야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e4fa4",
   "metadata": {},
   "source": [
    "xgboost 모듈의 train() 함수를 호출하며 학습을 수행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84c9bb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.65016\teval-logloss:0.66183\n",
      "[1]\ttrain-logloss:0.61131\teval-logloss:0.63609\n",
      "[2]\ttrain-logloss:0.57563\teval-logloss:0.61144\n",
      "[3]\ttrain-logloss:0.54310\teval-logloss:0.59204\n",
      "[4]\ttrain-logloss:0.51323\teval-logloss:0.57329\n",
      "[5]\ttrain-logloss:0.48447\teval-logloss:0.55037\n",
      "[6]\ttrain-logloss:0.45796\teval-logloss:0.52929\n",
      "[7]\ttrain-logloss:0.43436\teval-logloss:0.51534\n",
      "[8]\ttrain-logloss:0.41150\teval-logloss:0.49718\n",
      "[9]\ttrain-logloss:0.39027\teval-logloss:0.48154\n",
      "[10]\ttrain-logloss:0.37128\teval-logloss:0.46990\n",
      "[11]\ttrain-logloss:0.35254\teval-logloss:0.45474\n",
      "[12]\ttrain-logloss:0.33528\teval-logloss:0.44229\n",
      "[13]\ttrain-logloss:0.31893\teval-logloss:0.42961\n",
      "[14]\ttrain-logloss:0.30439\teval-logloss:0.42065\n",
      "[15]\ttrain-logloss:0.29000\teval-logloss:0.40958\n",
      "[16]\ttrain-logloss:0.27651\teval-logloss:0.39887\n",
      "[17]\ttrain-logloss:0.26389\teval-logloss:0.39050\n",
      "[18]\ttrain-logloss:0.25210\teval-logloss:0.38254\n",
      "[19]\ttrain-logloss:0.24123\teval-logloss:0.37393\n",
      "[20]\ttrain-logloss:0.23076\teval-logloss:0.36789\n",
      "[21]\ttrain-logloss:0.22091\teval-logloss:0.36017\n",
      "[22]\ttrain-logloss:0.21155\teval-logloss:0.35421\n",
      "[23]\ttrain-logloss:0.20263\teval-logloss:0.34683\n",
      "[24]\ttrain-logloss:0.19434\teval-logloss:0.34111\n",
      "[25]\ttrain-logloss:0.18637\teval-logloss:0.33634\n",
      "[26]\ttrain-logloss:0.17875\teval-logloss:0.33082\n",
      "[27]\ttrain-logloss:0.17167\teval-logloss:0.32675\n",
      "[28]\ttrain-logloss:0.16481\teval-logloss:0.32099\n",
      "[29]\ttrain-logloss:0.15835\teval-logloss:0.31671\n",
      "[30]\ttrain-logloss:0.15225\teval-logloss:0.31277\n",
      "[31]\ttrain-logloss:0.14650\teval-logloss:0.30882\n",
      "[32]\ttrain-logloss:0.14102\teval-logloss:0.30437\n",
      "[33]\ttrain-logloss:0.13590\teval-logloss:0.30103\n",
      "[34]\ttrain-logloss:0.13109\teval-logloss:0.29794\n",
      "[35]\ttrain-logloss:0.12647\teval-logloss:0.29499\n",
      "[36]\ttrain-logloss:0.12197\teval-logloss:0.29295\n",
      "[37]\ttrain-logloss:0.11784\teval-logloss:0.29043\n",
      "[38]\ttrain-logloss:0.11379\teval-logloss:0.28927\n",
      "[39]\ttrain-logloss:0.10994\teval-logloss:0.28578\n",
      "[40]\ttrain-logloss:0.10638\teval-logloss:0.28364\n",
      "[41]\ttrain-logloss:0.10302\teval-logloss:0.28183\n",
      "[42]\ttrain-logloss:0.09963\teval-logloss:0.28005\n",
      "[43]\ttrain-logloss:0.09649\teval-logloss:0.27972\n",
      "[44]\ttrain-logloss:0.09359\teval-logloss:0.27744\n",
      "[45]\ttrain-logloss:0.09080\teval-logloss:0.27542\n",
      "[46]\ttrain-logloss:0.08807\teval-logloss:0.27504\n",
      "[47]\ttrain-logloss:0.08541\teval-logloss:0.27458\n",
      "[48]\ttrain-logloss:0.08299\teval-logloss:0.27348\n",
      "[49]\ttrain-logloss:0.08035\teval-logloss:0.27247\n",
      "[50]\ttrain-logloss:0.07786\teval-logloss:0.27163\n",
      "[51]\ttrain-logloss:0.07550\teval-logloss:0.27094\n",
      "[52]\ttrain-logloss:0.07344\teval-logloss:0.26967\n",
      "[53]\ttrain-logloss:0.07147\teval-logloss:0.27008\n",
      "[54]\ttrain-logloss:0.06964\teval-logloss:0.26890\n",
      "[55]\ttrain-logloss:0.06766\teval-logloss:0.26854\n",
      "[56]\ttrain-logloss:0.06592\teval-logloss:0.26900\n",
      "[57]\ttrain-logloss:0.06433\teval-logloss:0.26790\n",
      "[58]\ttrain-logloss:0.06259\teval-logloss:0.26663\n",
      "[59]\ttrain-logloss:0.06107\teval-logloss:0.26743\n",
      "[60]\ttrain-logloss:0.05957\teval-logloss:0.26610\n",
      "[61]\ttrain-logloss:0.05817\teval-logloss:0.26644\n",
      "[62]\ttrain-logloss:0.05691\teval-logloss:0.26673\n",
      "[63]\ttrain-logloss:0.05550\teval-logloss:0.26550\n",
      "[64]\ttrain-logloss:0.05422\teval-logloss:0.26443\n",
      "[65]\ttrain-logloss:0.05311\teval-logloss:0.26500\n",
      "[66]\ttrain-logloss:0.05207\teval-logloss:0.26591\n",
      "[67]\ttrain-logloss:0.05093\teval-logloss:0.26501\n",
      "[68]\ttrain-logloss:0.04976\teval-logloss:0.26435\n",
      "[69]\ttrain-logloss:0.04872\teval-logloss:0.26360\n",
      "[70]\ttrain-logloss:0.04776\teval-logloss:0.26319\n",
      "[71]\ttrain-logloss:0.04680\teval-logloss:0.26255\n",
      "[72]\ttrain-logloss:0.04580\teval-logloss:0.26204\n",
      "[73]\ttrain-logloss:0.04484\teval-logloss:0.26254\n",
      "[74]\ttrain-logloss:0.04388\teval-logloss:0.26289\n",
      "[75]\ttrain-logloss:0.04309\teval-logloss:0.26249\n",
      "[76]\ttrain-logloss:0.04224\teval-logloss:0.26217\n",
      "[77]\ttrain-logloss:0.04133\teval-logloss:0.26166\n",
      "[78]\ttrain-logloss:0.04050\teval-logloss:0.26179\n",
      "[79]\ttrain-logloss:0.03967\teval-logloss:0.26103\n",
      "[80]\ttrain-logloss:0.03877\teval-logloss:0.26094\n",
      "[81]\ttrain-logloss:0.03806\teval-logloss:0.26148\n",
      "[82]\ttrain-logloss:0.03740\teval-logloss:0.26054\n",
      "[83]\ttrain-logloss:0.03676\teval-logloss:0.25967\n",
      "[84]\ttrain-logloss:0.03605\teval-logloss:0.25905\n",
      "[85]\ttrain-logloss:0.03545\teval-logloss:0.26007\n",
      "[86]\ttrain-logloss:0.03488\teval-logloss:0.25984\n",
      "[87]\ttrain-logloss:0.03425\teval-logloss:0.25933\n",
      "[88]\ttrain-logloss:0.03361\teval-logloss:0.25932\n",
      "[89]\ttrain-logloss:0.03311\teval-logloss:0.26002\n",
      "[90]\ttrain-logloss:0.03260\teval-logloss:0.25936\n",
      "[91]\ttrain-logloss:0.03202\teval-logloss:0.25886\n",
      "[92]\ttrain-logloss:0.03152\teval-logloss:0.25918\n",
      "[93]\ttrain-logloss:0.03107\teval-logloss:0.25865\n",
      "[94]\ttrain-logloss:0.03049\teval-logloss:0.25951\n",
      "[95]\ttrain-logloss:0.03007\teval-logloss:0.26091\n",
      "[96]\ttrain-logloss:0.02963\teval-logloss:0.26014\n",
      "[97]\ttrain-logloss:0.02913\teval-logloss:0.25974\n",
      "[98]\ttrain-logloss:0.02866\teval-logloss:0.25937\n",
      "[99]\ttrain-logloss:0.02829\teval-logloss:0.25893\n",
      "[100]\ttrain-logloss:0.02789\teval-logloss:0.25928\n",
      "[101]\ttrain-logloss:0.02751\teval-logloss:0.25955\n",
      "[102]\ttrain-logloss:0.02714\teval-logloss:0.25901\n",
      "[103]\ttrain-logloss:0.02668\teval-logloss:0.25991\n",
      "[104]\ttrain-logloss:0.02634\teval-logloss:0.25950\n",
      "[105]\ttrain-logloss:0.02594\teval-logloss:0.25924\n",
      "[106]\ttrain-logloss:0.02556\teval-logloss:0.25901\n",
      "[107]\ttrain-logloss:0.02522\teval-logloss:0.25738\n",
      "[108]\ttrain-logloss:0.02492\teval-logloss:0.25702\n",
      "[109]\ttrain-logloss:0.02453\teval-logloss:0.25789\n",
      "[110]\ttrain-logloss:0.02418\teval-logloss:0.25770\n",
      "[111]\ttrain-logloss:0.02384\teval-logloss:0.25842\n",
      "[112]\ttrain-logloss:0.02356\teval-logloss:0.25810\n",
      "[113]\ttrain-logloss:0.02322\teval-logloss:0.25848\n",
      "[114]\ttrain-logloss:0.02290\teval-logloss:0.25833\n",
      "[115]\ttrain-logloss:0.02260\teval-logloss:0.25820\n",
      "[116]\ttrain-logloss:0.02229\teval-logloss:0.25905\n",
      "[117]\ttrain-logloss:0.02204\teval-logloss:0.25878\n",
      "[118]\ttrain-logloss:0.02176\teval-logloss:0.25728\n",
      "[119]\ttrain-logloss:0.02149\teval-logloss:0.25722\n",
      "[120]\ttrain-logloss:0.02119\teval-logloss:0.25764\n",
      "[121]\ttrain-logloss:0.02095\teval-logloss:0.25761\n",
      "[122]\ttrain-logloss:0.02067\teval-logloss:0.25832\n",
      "[123]\ttrain-logloss:0.02045\teval-logloss:0.25808\n",
      "[124]\ttrain-logloss:0.02023\teval-logloss:0.25855\n",
      "[125]\ttrain-logloss:0.01998\teval-logloss:0.25714\n",
      "[126]\ttrain-logloss:0.01973\teval-logloss:0.25587\n",
      "[127]\ttrain-logloss:0.01946\teval-logloss:0.25640\n",
      "[128]\ttrain-logloss:0.01927\teval-logloss:0.25685\n",
      "[129]\ttrain-logloss:0.01908\teval-logloss:0.25665\n",
      "[130]\ttrain-logloss:0.01886\teval-logloss:0.25712\n",
      "[131]\ttrain-logloss:0.01863\teval-logloss:0.25609\n",
      "[132]\ttrain-logloss:0.01839\teval-logloss:0.25649\n",
      "[133]\ttrain-logloss:0.01816\teval-logloss:0.25789\n",
      "[134]\ttrain-logloss:0.01802\teval-logloss:0.25811\n",
      "[135]\ttrain-logloss:0.01785\teval-logloss:0.25794\n",
      "[136]\ttrain-logloss:0.01763\teval-logloss:0.25876\n",
      "[137]\ttrain-logloss:0.01748\teval-logloss:0.25884\n",
      "[138]\ttrain-logloss:0.01732\teval-logloss:0.25867\n",
      "[139]\ttrain-logloss:0.01719\teval-logloss:0.25876\n",
      "[140]\ttrain-logloss:0.01696\teval-logloss:0.25987\n",
      "[141]\ttrain-logloss:0.01681\teval-logloss:0.25960\n",
      "[142]\ttrain-logloss:0.01669\teval-logloss:0.25982\n",
      "[143]\ttrain-logloss:0.01656\teval-logloss:0.25992\n",
      "[144]\ttrain-logloss:0.01638\teval-logloss:0.26035\n",
      "[145]\ttrain-logloss:0.01623\teval-logloss:0.26055\n",
      "[146]\ttrain-logloss:0.01606\teval-logloss:0.26092\n",
      "[147]\ttrain-logloss:0.01589\teval-logloss:0.26137\n",
      "[148]\ttrain-logloss:0.01572\teval-logloss:0.25999\n",
      "[149]\ttrain-logloss:0.01557\teval-logloss:0.26028\n",
      "[150]\ttrain-logloss:0.01546\teval-logloss:0.26048\n",
      "[151]\ttrain-logloss:0.01531\teval-logloss:0.26142\n",
      "[152]\ttrain-logloss:0.01515\teval-logloss:0.26188\n",
      "[153]\ttrain-logloss:0.01501\teval-logloss:0.26227\n",
      "[154]\ttrain-logloss:0.01486\teval-logloss:0.26287\n",
      "[155]\ttrain-logloss:0.01476\teval-logloss:0.26299\n",
      "[156]\ttrain-logloss:0.01461\teval-logloss:0.26346\n",
      "[157]\ttrain-logloss:0.01448\teval-logloss:0.26379\n",
      "[158]\ttrain-logloss:0.01434\teval-logloss:0.26306\n",
      "[159]\ttrain-logloss:0.01424\teval-logloss:0.26237\n",
      "[160]\ttrain-logloss:0.01410\teval-logloss:0.26251\n",
      "[161]\ttrain-logloss:0.01401\teval-logloss:0.26265\n",
      "[162]\ttrain-logloss:0.01392\teval-logloss:0.26264\n",
      "[163]\ttrain-logloss:0.01380\teval-logloss:0.26250\n",
      "[164]\ttrain-logloss:0.01372\teval-logloss:0.26264\n",
      "[165]\ttrain-logloss:0.01359\teval-logloss:0.26255\n",
      "[166]\ttrain-logloss:0.01350\teval-logloss:0.26188\n",
      "[167]\ttrain-logloss:0.01342\teval-logloss:0.26203\n",
      "[168]\ttrain-logloss:0.01331\teval-logloss:0.26190\n",
      "[169]\ttrain-logloss:0.01319\teval-logloss:0.26184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170]\ttrain-logloss:0.01312\teval-logloss:0.26133\n",
      "[171]\ttrain-logloss:0.01304\teval-logloss:0.26148\n",
      "[172]\ttrain-logloss:0.01297\teval-logloss:0.26157\n",
      "[173]\ttrain-logloss:0.01285\teval-logloss:0.26253\n",
      "[174]\ttrain-logloss:0.01278\teval-logloss:0.26229\n",
      "[175]\ttrain-logloss:0.01267\teval-logloss:0.26086\n",
      "[176]\ttrain-logloss:0.01258\teval-logloss:0.26103\n"
     ]
    }
   ],
   "source": [
    "# gㅏㄱ습 데이터 셋은 'train' 또는 평가 데이터 셋은 'eval'로 지정한다. \n",
    "eval_list = [(dtr, 'train'), (dval, 'eval')] \n",
    "# 혹은 eval_list = [(dval, 'eval')]로만 지정해도 된다. \n",
    "\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train() 함수의 파라미터로 전달한다. \n",
    "xgb_model = xgb.train(params, dtrain = dtr, num_boost_round = num_rounds, \\\n",
    "                      early_stopping_rounds = 50, evals = eval_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33109b40",
   "metadata": {},
   "source": [
    "파이썬 래퍼 XGBoost는 train() 함수를 호출해 학습이 완료된 모데르 객체를 반환하게 되는데, 이 모델 객체는 예측을 위해 predict() 메서드를 이용한다. <br> \n",
    "유의해야 하는 점은 **사이킷런의 predict() 메서드는 예측 결과를 클래스 값(0, 1)을 반환하는데 반해 xgboost의 predict()는 예측 결과값이 아닌 \n",
    "예측 결과를 추정할 수 있는 확률 값을 반환한다는 것**이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90dba7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시된다.\n",
      "[0.845 0.008 0.68  0.081 0.975 0.999 0.998 0.998 0.996 0.001]\n",
      "예측값 10개만 표시 :  [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시된다.')\n",
    "print(np.round(pred_probs[:10], 3))\n",
    "\n",
    "# 예측 확률이 0.5보다 크면 1, 그렇지 않으면 0으로 예측 값을 결정해 List 객체인 preds에 저장한다.\n",
    "preds = [1 if x > 0.5 else 0 for x in pred_probs]\n",
    "print('예측값 10개만 표시 : ', preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed86dd5",
   "metadata": {},
   "source": [
    "테스트 실제 레이블 값을 가지는 Y_test와 예측 레이블인 preds, 그리고 예측 확률인 pred_proba를 인자로 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77f1573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 get_clf_eval() Data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(Y_test, pred = None, pred_proba = None):\n",
    "    confusion = confusion_matrix(Y_test, pred)\n",
    "    accuracy = accuracy_score(Y_test, pred)\n",
    "    precision = precision_score(Y_test, pred)\n",
    "    recall = recall_score(Y_test, pred)\n",
    "    f1 = f1_score(Y_test, pred)\n",
    "    \n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(Y_test, pred)\n",
    "     \n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(Y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    \n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도 : {0:.4f}, 정밀도 : {1:.4f}, 재현율 : {2:.4f}, F1 : {3:.4f}, AUC : {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc099f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[34  3]\n",
      " [ 2 75]]\n",
      "정확도 : 0.9561, 정밀도 : 0.9615, 재현율 : 0.9740, F1 : 0.9677, AUC : 0.9937\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(Y_test, preds, pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa48e5",
   "metadata": {},
   "source": [
    "파이썬 래퍼 XGBoost는 사이킷런의 GridSearchCV와 유사하게 데이터 세트에 대한 교차 검증 수행 후 최적 파라미터를 구할 수 있는 방법을 cv() API로 제공한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ec62c",
   "metadata": {},
   "source": [
    "### 사이킷런 래퍼 XGBoost의 개요 및 적용\n",
    "\n",
    "사이킷런 전용 XGBoost는 기본 Estimator를 그대로 상속해 만들었기 때문에 다른 Estimator와 동일하게 fit()과 predict()만으로 학습과 예측이 가능하고, 사이킷런의 유틸리티를 그대로 사용할 수 있다. <br>\n",
    "**분류를 위한 래퍼 클래스인 XGBClassifier**와 **회귀를 위한 래퍼 클래스인 XGBRegressor**로 나눌 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6394dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 래퍼 XGBoost 래퍼 클래스인 XBGClassifier import\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Warning 메시지를 없애기 위해 eval_metric 값을 XGBClassifier 생성 인자로 입력한다. \n",
    "xgb_wrapper = XGBClassifier(n_estimators = 400, learning_rate = 0.05, max_depth = 3, eval_metric = 'logloss')\n",
    "xgb_wrapper.fit(X_train, Y_train, verbose = True)\n",
    "w_preds = xgb_wrapper.predict(X_test)\n",
    "w_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c6b18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[34  3]\n",
      " [ 1 76]]\n",
      "정확도 : 0.9649, 정밀도 : 0.9620, 재현율 : 0.9870, F1 : 0.9744, AUC : 0.9954\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(Y_test, w_preds, w_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bd346d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.65016\tvalidation_1-logloss:0.66183\n",
      "[1]\tvalidation_0-logloss:0.61131\tvalidation_1-logloss:0.63609\n",
      "[2]\tvalidation_0-logloss:0.57563\tvalidation_1-logloss:0.61144\n",
      "[3]\tvalidation_0-logloss:0.54310\tvalidation_1-logloss:0.59204\n",
      "[4]\tvalidation_0-logloss:0.51323\tvalidation_1-logloss:0.57329\n",
      "[5]\tvalidation_0-logloss:0.48447\tvalidation_1-logloss:0.55037\n",
      "[6]\tvalidation_0-logloss:0.45796\tvalidation_1-logloss:0.52929\n",
      "[7]\tvalidation_0-logloss:0.43436\tvalidation_1-logloss:0.51534\n",
      "[8]\tvalidation_0-logloss:0.41150\tvalidation_1-logloss:0.49718\n",
      "[9]\tvalidation_0-logloss:0.39027\tvalidation_1-logloss:0.48154\n",
      "[10]\tvalidation_0-logloss:0.37128\tvalidation_1-logloss:0.46990\n",
      "[11]\tvalidation_0-logloss:0.35254\tvalidation_1-logloss:0.45474\n",
      "[12]\tvalidation_0-logloss:0.33528\tvalidation_1-logloss:0.44229\n",
      "[13]\tvalidation_0-logloss:0.31893\tvalidation_1-logloss:0.42961\n",
      "[14]\tvalidation_0-logloss:0.30439\tvalidation_1-logloss:0.42065\n",
      "[15]\tvalidation_0-logloss:0.29000\tvalidation_1-logloss:0.40958\n",
      "[16]\tvalidation_0-logloss:0.27651\tvalidation_1-logloss:0.39887\n",
      "[17]\tvalidation_0-logloss:0.26389\tvalidation_1-logloss:0.39050\n",
      "[18]\tvalidation_0-logloss:0.25210\tvalidation_1-logloss:0.38254\n",
      "[19]\tvalidation_0-logloss:0.24123\tvalidation_1-logloss:0.37393\n",
      "[20]\tvalidation_0-logloss:0.23076\tvalidation_1-logloss:0.36789\n",
      "[21]\tvalidation_0-logloss:0.22091\tvalidation_1-logloss:0.36017\n",
      "[22]\tvalidation_0-logloss:0.21155\tvalidation_1-logloss:0.35421\n",
      "[23]\tvalidation_0-logloss:0.20263\tvalidation_1-logloss:0.34683\n",
      "[24]\tvalidation_0-logloss:0.19434\tvalidation_1-logloss:0.34111\n",
      "[25]\tvalidation_0-logloss:0.18637\tvalidation_1-logloss:0.33634\n",
      "[26]\tvalidation_0-logloss:0.17875\tvalidation_1-logloss:0.33082\n",
      "[27]\tvalidation_0-logloss:0.17167\tvalidation_1-logloss:0.32675\n",
      "[28]\tvalidation_0-logloss:0.16481\tvalidation_1-logloss:0.32099\n",
      "[29]\tvalidation_0-logloss:0.15835\tvalidation_1-logloss:0.31671\n",
      "[30]\tvalidation_0-logloss:0.15225\tvalidation_1-logloss:0.31277\n",
      "[31]\tvalidation_0-logloss:0.14650\tvalidation_1-logloss:0.30882\n",
      "[32]\tvalidation_0-logloss:0.14102\tvalidation_1-logloss:0.30437\n",
      "[33]\tvalidation_0-logloss:0.13590\tvalidation_1-logloss:0.30103\n",
      "[34]\tvalidation_0-logloss:0.13109\tvalidation_1-logloss:0.29794\n",
      "[35]\tvalidation_0-logloss:0.12647\tvalidation_1-logloss:0.29499\n",
      "[36]\tvalidation_0-logloss:0.12197\tvalidation_1-logloss:0.29295\n",
      "[37]\tvalidation_0-logloss:0.11784\tvalidation_1-logloss:0.29043\n",
      "[38]\tvalidation_0-logloss:0.11379\tvalidation_1-logloss:0.28927\n",
      "[39]\tvalidation_0-logloss:0.10994\tvalidation_1-logloss:0.28578\n",
      "[40]\tvalidation_0-logloss:0.10638\tvalidation_1-logloss:0.28364\n",
      "[41]\tvalidation_0-logloss:0.10302\tvalidation_1-logloss:0.28183\n",
      "[42]\tvalidation_0-logloss:0.09963\tvalidation_1-logloss:0.28005\n",
      "[43]\tvalidation_0-logloss:0.09649\tvalidation_1-logloss:0.27972\n",
      "[44]\tvalidation_0-logloss:0.09359\tvalidation_1-logloss:0.27744\n",
      "[45]\tvalidation_0-logloss:0.09080\tvalidation_1-logloss:0.27542\n",
      "[46]\tvalidation_0-logloss:0.08807\tvalidation_1-logloss:0.27504\n",
      "[47]\tvalidation_0-logloss:0.08541\tvalidation_1-logloss:0.27458\n",
      "[48]\tvalidation_0-logloss:0.08299\tvalidation_1-logloss:0.27348\n",
      "[49]\tvalidation_0-logloss:0.08035\tvalidation_1-logloss:0.27247\n",
      "[50]\tvalidation_0-logloss:0.07786\tvalidation_1-logloss:0.27163\n",
      "[51]\tvalidation_0-logloss:0.07550\tvalidation_1-logloss:0.27094\n",
      "[52]\tvalidation_0-logloss:0.07344\tvalidation_1-logloss:0.26967\n",
      "[53]\tvalidation_0-logloss:0.07147\tvalidation_1-logloss:0.27008\n",
      "[54]\tvalidation_0-logloss:0.06964\tvalidation_1-logloss:0.26890\n",
      "[55]\tvalidation_0-logloss:0.06766\tvalidation_1-logloss:0.26854\n",
      "[56]\tvalidation_0-logloss:0.06592\tvalidation_1-logloss:0.26900\n",
      "[57]\tvalidation_0-logloss:0.06433\tvalidation_1-logloss:0.26790\n",
      "[58]\tvalidation_0-logloss:0.06259\tvalidation_1-logloss:0.26663\n",
      "[59]\tvalidation_0-logloss:0.06107\tvalidation_1-logloss:0.26743\n",
      "[60]\tvalidation_0-logloss:0.05957\tvalidation_1-logloss:0.26610\n",
      "[61]\tvalidation_0-logloss:0.05817\tvalidation_1-logloss:0.26644\n",
      "[62]\tvalidation_0-logloss:0.05691\tvalidation_1-logloss:0.26673\n",
      "[63]\tvalidation_0-logloss:0.05550\tvalidation_1-logloss:0.26550\n",
      "[64]\tvalidation_0-logloss:0.05422\tvalidation_1-logloss:0.26443\n",
      "[65]\tvalidation_0-logloss:0.05311\tvalidation_1-logloss:0.26500\n",
      "[66]\tvalidation_0-logloss:0.05207\tvalidation_1-logloss:0.26591\n",
      "[67]\tvalidation_0-logloss:0.05093\tvalidation_1-logloss:0.26501\n",
      "[68]\tvalidation_0-logloss:0.04976\tvalidation_1-logloss:0.26435\n",
      "[69]\tvalidation_0-logloss:0.04872\tvalidation_1-logloss:0.26360\n",
      "[70]\tvalidation_0-logloss:0.04776\tvalidation_1-logloss:0.26319\n",
      "[71]\tvalidation_0-logloss:0.04680\tvalidation_1-logloss:0.26255\n",
      "[72]\tvalidation_0-logloss:0.04580\tvalidation_1-logloss:0.26204\n",
      "[73]\tvalidation_0-logloss:0.04484\tvalidation_1-logloss:0.26254\n",
      "[74]\tvalidation_0-logloss:0.04388\tvalidation_1-logloss:0.26289\n",
      "[75]\tvalidation_0-logloss:0.04309\tvalidation_1-logloss:0.26249\n",
      "[76]\tvalidation_0-logloss:0.04224\tvalidation_1-logloss:0.26217\n",
      "[77]\tvalidation_0-logloss:0.04133\tvalidation_1-logloss:0.26166\n",
      "[78]\tvalidation_0-logloss:0.04050\tvalidation_1-logloss:0.26179\n",
      "[79]\tvalidation_0-logloss:0.03967\tvalidation_1-logloss:0.26103\n",
      "[80]\tvalidation_0-logloss:0.03877\tvalidation_1-logloss:0.26094\n",
      "[81]\tvalidation_0-logloss:0.03806\tvalidation_1-logloss:0.26148\n",
      "[82]\tvalidation_0-logloss:0.03740\tvalidation_1-logloss:0.26054\n",
      "[83]\tvalidation_0-logloss:0.03676\tvalidation_1-logloss:0.25967\n",
      "[84]\tvalidation_0-logloss:0.03605\tvalidation_1-logloss:0.25905\n",
      "[85]\tvalidation_0-logloss:0.03545\tvalidation_1-logloss:0.26007\n",
      "[86]\tvalidation_0-logloss:0.03488\tvalidation_1-logloss:0.25984\n",
      "[87]\tvalidation_0-logloss:0.03425\tvalidation_1-logloss:0.25933\n",
      "[88]\tvalidation_0-logloss:0.03361\tvalidation_1-logloss:0.25932\n",
      "[89]\tvalidation_0-logloss:0.03311\tvalidation_1-logloss:0.26002\n",
      "[90]\tvalidation_0-logloss:0.03260\tvalidation_1-logloss:0.25936\n",
      "[91]\tvalidation_0-logloss:0.03202\tvalidation_1-logloss:0.25886\n",
      "[92]\tvalidation_0-logloss:0.03152\tvalidation_1-logloss:0.25918\n",
      "[93]\tvalidation_0-logloss:0.03107\tvalidation_1-logloss:0.25865\n",
      "[94]\tvalidation_0-logloss:0.03049\tvalidation_1-logloss:0.25951\n",
      "[95]\tvalidation_0-logloss:0.03007\tvalidation_1-logloss:0.26091\n",
      "[96]\tvalidation_0-logloss:0.02963\tvalidation_1-logloss:0.26014\n",
      "[97]\tvalidation_0-logloss:0.02913\tvalidation_1-logloss:0.25974\n",
      "[98]\tvalidation_0-logloss:0.02866\tvalidation_1-logloss:0.25937\n",
      "[99]\tvalidation_0-logloss:0.02829\tvalidation_1-logloss:0.25893\n",
      "[100]\tvalidation_0-logloss:0.02789\tvalidation_1-logloss:0.25928\n",
      "[101]\tvalidation_0-logloss:0.02751\tvalidation_1-logloss:0.25955\n",
      "[102]\tvalidation_0-logloss:0.02714\tvalidation_1-logloss:0.25901\n",
      "[103]\tvalidation_0-logloss:0.02668\tvalidation_1-logloss:0.25991\n",
      "[104]\tvalidation_0-logloss:0.02634\tvalidation_1-logloss:0.25950\n",
      "[105]\tvalidation_0-logloss:0.02594\tvalidation_1-logloss:0.25924\n",
      "[106]\tvalidation_0-logloss:0.02556\tvalidation_1-logloss:0.25901\n",
      "[107]\tvalidation_0-logloss:0.02522\tvalidation_1-logloss:0.25738\n",
      "[108]\tvalidation_0-logloss:0.02492\tvalidation_1-logloss:0.25702\n",
      "[109]\tvalidation_0-logloss:0.02453\tvalidation_1-logloss:0.25789\n",
      "[110]\tvalidation_0-logloss:0.02418\tvalidation_1-logloss:0.25770\n",
      "[111]\tvalidation_0-logloss:0.02384\tvalidation_1-logloss:0.25842\n",
      "[112]\tvalidation_0-logloss:0.02356\tvalidation_1-logloss:0.25810\n",
      "[113]\tvalidation_0-logloss:0.02322\tvalidation_1-logloss:0.25848\n",
      "[114]\tvalidation_0-logloss:0.02290\tvalidation_1-logloss:0.25833\n",
      "[115]\tvalidation_0-logloss:0.02260\tvalidation_1-logloss:0.25820\n",
      "[116]\tvalidation_0-logloss:0.02229\tvalidation_1-logloss:0.25905\n",
      "[117]\tvalidation_0-logloss:0.02204\tvalidation_1-logloss:0.25878\n",
      "[118]\tvalidation_0-logloss:0.02176\tvalidation_1-logloss:0.25728\n",
      "[119]\tvalidation_0-logloss:0.02149\tvalidation_1-logloss:0.25722\n",
      "[120]\tvalidation_0-logloss:0.02119\tvalidation_1-logloss:0.25764\n",
      "[121]\tvalidation_0-logloss:0.02095\tvalidation_1-logloss:0.25761\n",
      "[122]\tvalidation_0-logloss:0.02067\tvalidation_1-logloss:0.25832\n",
      "[123]\tvalidation_0-logloss:0.02045\tvalidation_1-logloss:0.25808\n",
      "[124]\tvalidation_0-logloss:0.02023\tvalidation_1-logloss:0.25855\n",
      "[125]\tvalidation_0-logloss:0.01998\tvalidation_1-logloss:0.25714\n",
      "[126]\tvalidation_0-logloss:0.01973\tvalidation_1-logloss:0.25587\n",
      "[127]\tvalidation_0-logloss:0.01946\tvalidation_1-logloss:0.25640\n",
      "[128]\tvalidation_0-logloss:0.01927\tvalidation_1-logloss:0.25685\n",
      "[129]\tvalidation_0-logloss:0.01908\tvalidation_1-logloss:0.25665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130]\tvalidation_0-logloss:0.01886\tvalidation_1-logloss:0.25712\n",
      "[131]\tvalidation_0-logloss:0.01863\tvalidation_1-logloss:0.25609\n",
      "[132]\tvalidation_0-logloss:0.01839\tvalidation_1-logloss:0.25649\n",
      "[133]\tvalidation_0-logloss:0.01816\tvalidation_1-logloss:0.25789\n",
      "[134]\tvalidation_0-logloss:0.01802\tvalidation_1-logloss:0.25811\n",
      "[135]\tvalidation_0-logloss:0.01785\tvalidation_1-logloss:0.25794\n",
      "[136]\tvalidation_0-logloss:0.01763\tvalidation_1-logloss:0.25876\n",
      "[137]\tvalidation_0-logloss:0.01748\tvalidation_1-logloss:0.25884\n",
      "[138]\tvalidation_0-logloss:0.01732\tvalidation_1-logloss:0.25867\n",
      "[139]\tvalidation_0-logloss:0.01719\tvalidation_1-logloss:0.25876\n",
      "[140]\tvalidation_0-logloss:0.01696\tvalidation_1-logloss:0.25987\n",
      "[141]\tvalidation_0-logloss:0.01681\tvalidation_1-logloss:0.25960\n",
      "[142]\tvalidation_0-logloss:0.01669\tvalidation_1-logloss:0.25982\n",
      "[143]\tvalidation_0-logloss:0.01656\tvalidation_1-logloss:0.25992\n",
      "[144]\tvalidation_0-logloss:0.01638\tvalidation_1-logloss:0.26035\n",
      "[145]\tvalidation_0-logloss:0.01623\tvalidation_1-logloss:0.26055\n",
      "[146]\tvalidation_0-logloss:0.01606\tvalidation_1-logloss:0.26092\n",
      "[147]\tvalidation_0-logloss:0.01589\tvalidation_1-logloss:0.26137\n",
      "[148]\tvalidation_0-logloss:0.01572\tvalidation_1-logloss:0.25999\n",
      "[149]\tvalidation_0-logloss:0.01557\tvalidation_1-logloss:0.26028\n",
      "[150]\tvalidation_0-logloss:0.01546\tvalidation_1-logloss:0.26048\n",
      "[151]\tvalidation_0-logloss:0.01531\tvalidation_1-logloss:0.26142\n",
      "[152]\tvalidation_0-logloss:0.01515\tvalidation_1-logloss:0.26188\n",
      "[153]\tvalidation_0-logloss:0.01501\tvalidation_1-logloss:0.26227\n",
      "[154]\tvalidation_0-logloss:0.01486\tvalidation_1-logloss:0.26287\n",
      "[155]\tvalidation_0-logloss:0.01476\tvalidation_1-logloss:0.26299\n",
      "[156]\tvalidation_0-logloss:0.01461\tvalidation_1-logloss:0.26346\n",
      "[157]\tvalidation_0-logloss:0.01448\tvalidation_1-logloss:0.26379\n",
      "[158]\tvalidation_0-logloss:0.01434\tvalidation_1-logloss:0.26306\n",
      "[159]\tvalidation_0-logloss:0.01424\tvalidation_1-logloss:0.26237\n",
      "[160]\tvalidation_0-logloss:0.01410\tvalidation_1-logloss:0.26251\n",
      "[161]\tvalidation_0-logloss:0.01401\tvalidation_1-logloss:0.26265\n",
      "[162]\tvalidation_0-logloss:0.01392\tvalidation_1-logloss:0.26264\n",
      "[163]\tvalidation_0-logloss:0.01380\tvalidation_1-logloss:0.26250\n",
      "[164]\tvalidation_0-logloss:0.01372\tvalidation_1-logloss:0.26264\n",
      "[165]\tvalidation_0-logloss:0.01359\tvalidation_1-logloss:0.26255\n",
      "[166]\tvalidation_0-logloss:0.01350\tvalidation_1-logloss:0.26188\n",
      "[167]\tvalidation_0-logloss:0.01342\tvalidation_1-logloss:0.26203\n",
      "[168]\tvalidation_0-logloss:0.01331\tvalidation_1-logloss:0.26190\n",
      "[169]\tvalidation_0-logloss:0.01319\tvalidation_1-logloss:0.26184\n",
      "[170]\tvalidation_0-logloss:0.01312\tvalidation_1-logloss:0.26133\n",
      "[171]\tvalidation_0-logloss:0.01304\tvalidation_1-logloss:0.26148\n",
      "[172]\tvalidation_0-logloss:0.01297\tvalidation_1-logloss:0.26157\n",
      "[173]\tvalidation_0-logloss:0.01285\tvalidation_1-logloss:0.26253\n",
      "[174]\tvalidation_0-logloss:0.01278\tvalidation_1-logloss:0.26229\n",
      "[175]\tvalidation_0-logloss:0.01267\tvalidation_1-logloss:0.26086\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_wrapper = XGBClassifier(n_estimators = 400, learning_rate = 0.05, max_depth = 3)\n",
    "evals = [(X_tr, Y_tr), (X_val, Y_val)]\n",
    "xgb_wrapper.fit(X_tr, Y_tr, early_stopping_rounds = 50, eval_metric = 'logloss', eval_set = evals, verbose = True)\n",
    "ws50_preds = xgb_wrapper.predict(X_test)\n",
    "ws50_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "173f395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[34  3]\n",
      " [ 2 75]]\n",
      "정확도 : 0.9561, 정밀도 : 0.9615, 재현율 : 0.9740, F1 : 0.9677, AUC : 0.9933\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(Y_test, ws50_preds, ws50_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5406c",
   "metadata": {},
   "source": [
    "하지만 조기 중단 값을 너무 급격하게 줄이면 예측 성능이 저하될 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10db0461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.65016\tvalidation_1-logloss:0.66183\n",
      "[1]\tvalidation_0-logloss:0.61131\tvalidation_1-logloss:0.63609\n",
      "[2]\tvalidation_0-logloss:0.57563\tvalidation_1-logloss:0.61144\n",
      "[3]\tvalidation_0-logloss:0.54310\tvalidation_1-logloss:0.59204\n",
      "[4]\tvalidation_0-logloss:0.51323\tvalidation_1-logloss:0.57329\n",
      "[5]\tvalidation_0-logloss:0.48447\tvalidation_1-logloss:0.55037\n",
      "[6]\tvalidation_0-logloss:0.45796\tvalidation_1-logloss:0.52929\n",
      "[7]\tvalidation_0-logloss:0.43436\tvalidation_1-logloss:0.51534\n",
      "[8]\tvalidation_0-logloss:0.41150\tvalidation_1-logloss:0.49718\n",
      "[9]\tvalidation_0-logloss:0.39027\tvalidation_1-logloss:0.48154\n",
      "[10]\tvalidation_0-logloss:0.37128\tvalidation_1-logloss:0.46990\n",
      "[11]\tvalidation_0-logloss:0.35254\tvalidation_1-logloss:0.45474\n",
      "[12]\tvalidation_0-logloss:0.33528\tvalidation_1-logloss:0.44229\n",
      "[13]\tvalidation_0-logloss:0.31893\tvalidation_1-logloss:0.42961\n",
      "[14]\tvalidation_0-logloss:0.30439\tvalidation_1-logloss:0.42065\n",
      "[15]\tvalidation_0-logloss:0.29000\tvalidation_1-logloss:0.40958\n",
      "[16]\tvalidation_0-logloss:0.27651\tvalidation_1-logloss:0.39887\n",
      "[17]\tvalidation_0-logloss:0.26389\tvalidation_1-logloss:0.39050\n",
      "[18]\tvalidation_0-logloss:0.25210\tvalidation_1-logloss:0.38254\n",
      "[19]\tvalidation_0-logloss:0.24123\tvalidation_1-logloss:0.37393\n",
      "[20]\tvalidation_0-logloss:0.23076\tvalidation_1-logloss:0.36789\n",
      "[21]\tvalidation_0-logloss:0.22091\tvalidation_1-logloss:0.36017\n",
      "[22]\tvalidation_0-logloss:0.21155\tvalidation_1-logloss:0.35421\n",
      "[23]\tvalidation_0-logloss:0.20263\tvalidation_1-logloss:0.34683\n",
      "[24]\tvalidation_0-logloss:0.19434\tvalidation_1-logloss:0.34111\n",
      "[25]\tvalidation_0-logloss:0.18637\tvalidation_1-logloss:0.33634\n",
      "[26]\tvalidation_0-logloss:0.17875\tvalidation_1-logloss:0.33082\n",
      "[27]\tvalidation_0-logloss:0.17167\tvalidation_1-logloss:0.32675\n",
      "[28]\tvalidation_0-logloss:0.16481\tvalidation_1-logloss:0.32099\n",
      "[29]\tvalidation_0-logloss:0.15835\tvalidation_1-logloss:0.31671\n",
      "[30]\tvalidation_0-logloss:0.15225\tvalidation_1-logloss:0.31277\n",
      "[31]\tvalidation_0-logloss:0.14650\tvalidation_1-logloss:0.30882\n",
      "[32]\tvalidation_0-logloss:0.14102\tvalidation_1-logloss:0.30437\n",
      "[33]\tvalidation_0-logloss:0.13590\tvalidation_1-logloss:0.30103\n",
      "[34]\tvalidation_0-logloss:0.13109\tvalidation_1-logloss:0.29794\n",
      "[35]\tvalidation_0-logloss:0.12647\tvalidation_1-logloss:0.29499\n",
      "[36]\tvalidation_0-logloss:0.12197\tvalidation_1-logloss:0.29295\n",
      "[37]\tvalidation_0-logloss:0.11784\tvalidation_1-logloss:0.29043\n",
      "[38]\tvalidation_0-logloss:0.11379\tvalidation_1-logloss:0.28927\n",
      "[39]\tvalidation_0-logloss:0.10994\tvalidation_1-logloss:0.28578\n",
      "[40]\tvalidation_0-logloss:0.10638\tvalidation_1-logloss:0.28364\n",
      "[41]\tvalidation_0-logloss:0.10302\tvalidation_1-logloss:0.28183\n",
      "[42]\tvalidation_0-logloss:0.09963\tvalidation_1-logloss:0.28005\n",
      "[43]\tvalidation_0-logloss:0.09649\tvalidation_1-logloss:0.27972\n",
      "[44]\tvalidation_0-logloss:0.09359\tvalidation_1-logloss:0.27744\n",
      "[45]\tvalidation_0-logloss:0.09080\tvalidation_1-logloss:0.27542\n",
      "[46]\tvalidation_0-logloss:0.08807\tvalidation_1-logloss:0.27504\n",
      "[47]\tvalidation_0-logloss:0.08541\tvalidation_1-logloss:0.27458\n",
      "[48]\tvalidation_0-logloss:0.08299\tvalidation_1-logloss:0.27348\n",
      "[49]\tvalidation_0-logloss:0.08035\tvalidation_1-logloss:0.27247\n",
      "[50]\tvalidation_0-logloss:0.07786\tvalidation_1-logloss:0.27163\n",
      "[51]\tvalidation_0-logloss:0.07550\tvalidation_1-logloss:0.27094\n",
      "[52]\tvalidation_0-logloss:0.07344\tvalidation_1-logloss:0.26967\n",
      "[53]\tvalidation_0-logloss:0.07147\tvalidation_1-logloss:0.27008\n",
      "[54]\tvalidation_0-logloss:0.06964\tvalidation_1-logloss:0.26890\n",
      "[55]\tvalidation_0-logloss:0.06766\tvalidation_1-logloss:0.26854\n",
      "[56]\tvalidation_0-logloss:0.06592\tvalidation_1-logloss:0.26900\n",
      "[57]\tvalidation_0-logloss:0.06433\tvalidation_1-logloss:0.26790\n",
      "[58]\tvalidation_0-logloss:0.06259\tvalidation_1-logloss:0.26663\n",
      "[59]\tvalidation_0-logloss:0.06107\tvalidation_1-logloss:0.26743\n",
      "[60]\tvalidation_0-logloss:0.05957\tvalidation_1-logloss:0.26610\n",
      "[61]\tvalidation_0-logloss:0.05817\tvalidation_1-logloss:0.26644\n",
      "[62]\tvalidation_0-logloss:0.05691\tvalidation_1-logloss:0.26673\n",
      "[63]\tvalidation_0-logloss:0.05550\tvalidation_1-logloss:0.26550\n",
      "[64]\tvalidation_0-logloss:0.05422\tvalidation_1-logloss:0.26443\n",
      "[65]\tvalidation_0-logloss:0.05311\tvalidation_1-logloss:0.26500\n",
      "[66]\tvalidation_0-logloss:0.05207\tvalidation_1-logloss:0.26591\n",
      "[67]\tvalidation_0-logloss:0.05093\tvalidation_1-logloss:0.26501\n",
      "[68]\tvalidation_0-logloss:0.04976\tvalidation_1-logloss:0.26435\n",
      "[69]\tvalidation_0-logloss:0.04872\tvalidation_1-logloss:0.26360\n",
      "[70]\tvalidation_0-logloss:0.04776\tvalidation_1-logloss:0.26319\n",
      "[71]\tvalidation_0-logloss:0.04680\tvalidation_1-logloss:0.26255\n",
      "[72]\tvalidation_0-logloss:0.04580\tvalidation_1-logloss:0.26204\n",
      "[73]\tvalidation_0-logloss:0.04484\tvalidation_1-logloss:0.26254\n",
      "[74]\tvalidation_0-logloss:0.04388\tvalidation_1-logloss:0.26289\n",
      "[75]\tvalidation_0-logloss:0.04309\tvalidation_1-logloss:0.26249\n",
      "[76]\tvalidation_0-logloss:0.04224\tvalidation_1-logloss:0.26217\n",
      "[77]\tvalidation_0-logloss:0.04133\tvalidation_1-logloss:0.26166\n",
      "[78]\tvalidation_0-logloss:0.04050\tvalidation_1-logloss:0.26179\n",
      "[79]\tvalidation_0-logloss:0.03967\tvalidation_1-logloss:0.26103\n",
      "[80]\tvalidation_0-logloss:0.03877\tvalidation_1-logloss:0.26094\n",
      "[81]\tvalidation_0-logloss:0.03806\tvalidation_1-logloss:0.26148\n",
      "[82]\tvalidation_0-logloss:0.03740\tvalidation_1-logloss:0.26054\n",
      "[83]\tvalidation_0-logloss:0.03676\tvalidation_1-logloss:0.25967\n",
      "[84]\tvalidation_0-logloss:0.03605\tvalidation_1-logloss:0.25905\n",
      "[85]\tvalidation_0-logloss:0.03545\tvalidation_1-logloss:0.26007\n",
      "[86]\tvalidation_0-logloss:0.03488\tvalidation_1-logloss:0.25984\n",
      "[87]\tvalidation_0-logloss:0.03425\tvalidation_1-logloss:0.25933\n",
      "[88]\tvalidation_0-logloss:0.03361\tvalidation_1-logloss:0.25932\n",
      "[89]\tvalidation_0-logloss:0.03311\tvalidation_1-logloss:0.26002\n",
      "[90]\tvalidation_0-logloss:0.03260\tvalidation_1-logloss:0.25936\n",
      "[91]\tvalidation_0-logloss:0.03202\tvalidation_1-logloss:0.25886\n",
      "[92]\tvalidation_0-logloss:0.03152\tvalidation_1-logloss:0.25918\n",
      "[93]\tvalidation_0-logloss:0.03107\tvalidation_1-logloss:0.25865\n",
      "[94]\tvalidation_0-logloss:0.03049\tvalidation_1-logloss:0.25951\n",
      "[95]\tvalidation_0-logloss:0.03007\tvalidation_1-logloss:0.26091\n",
      "[96]\tvalidation_0-logloss:0.02963\tvalidation_1-logloss:0.26014\n",
      "[97]\tvalidation_0-logloss:0.02913\tvalidation_1-logloss:0.25974\n",
      "[98]\tvalidation_0-logloss:0.02866\tvalidation_1-logloss:0.25937\n",
      "[99]\tvalidation_0-logloss:0.02829\tvalidation_1-logloss:0.25893\n",
      "[100]\tvalidation_0-logloss:0.02789\tvalidation_1-logloss:0.25928\n",
      "[101]\tvalidation_0-logloss:0.02751\tvalidation_1-logloss:0.25955\n",
      "[102]\tvalidation_0-logloss:0.02714\tvalidation_1-logloss:0.25901\n",
      "오차 행렬\n",
      "[[34  3]\n",
      " [ 3 74]]\n",
      "정확도 : 0.9474, 정밀도 : 0.9610, 재현율 : 0.9610, F1 : 0.9610, AUC : 0.9933\n"
     ]
    }
   ],
   "source": [
    "# early_stopping_rounds를 10으로 설정하고 재학습\n",
    "xgb_wrapper = XGBClassifier(n_estimators = 400, learning_rate = 0.05, max_depth = 3)\n",
    "evals = [(X_tr, Y_tr), (X_val, Y_val)]\n",
    "xgb_wrapper.fit(X_tr, Y_tr, early_stopping_rounds = 10, eval_metric = 'logloss', eval_set = evals, verbose = True)\n",
    "ws50_preds = xgb_wrapper.predict(X_test)\n",
    "ws50_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(Y_test, ws50_preds, ws50_pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
